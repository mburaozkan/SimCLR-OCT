{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042c1466-1d5b-461d-88c7-68ffb4a98199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/app/SimCLR-OCT/')  # Adjust this to your actual script path\n",
    "sys.argv = ['main_linear.py', '--batch_size', '32', '--dataset', 'oct', '--ckpt', '/app/SimCLR-OCT/save/SupCon/oct_models/SupCon_oct_resnet50_lr_0.05_decay_0.0001_bsz_8_temp_0.07_trial_0_cosine/ckpt_epoch_50.pth']\n",
    "\n",
    "# Now, you can import your modules and functions\n",
    "from main_linear import parse_option, set_model, train, validate\n",
    "from main_ce import set_loader\n",
    "from util import adjust_learning_rate, warmup_learning_rate, accuracy, set_optimizer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # For a nicer heatmap visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af337077-6662-46f3-9b8b-6bb88ca083e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metrics = {\n",
    "        'accuracy': 0,\n",
    "        'precision': 0,\n",
    "        'recall': 0,\n",
    "        'f1': 0,\n",
    "        'epoch': 0,  # To track at which epoch the best accuracy was found\n",
    "        'confusion_matrix': None  # To store the best confusion matrix\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ea801a-b070-4891-846f-1e969228cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=plt.cm.Blues, xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e77d31-6c92-48cc-ad43-dff5b254ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = parse_option()\n",
    "\n",
    "    # Assuming set_loader is defined elsewhere and correctly imported\n",
    "    train_loader, val_loader = set_loader(opt)\n",
    "\n",
    "    model, classifier, criterion = set_model(opt)\n",
    "    optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        adjust_learning_rate(opt, optimizer, epoch)\n",
    "\n",
    "        # Training phase\n",
    "        train_loss, train_acc = train(train_loader, model, classifier, criterion, optimizer, epoch, opt)\n",
    "        print(f'Train epoch {epoch}, loss: {train_loss:.4f}, accuracy: {train_acc:.2f}%')\n",
    "\n",
    "        # Validation phase with additional metrics\n",
    "        val_loss, val_acc, precision, recall, f1, confusion_mat = validate(val_loader, model, classifier, criterion, opt)\n",
    "\n",
    "        # Print validation results including new metrics\n",
    "        print(f'Validation epoch {epoch}: Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%, '\n",
    "              f'Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}, ')\n",
    "\n",
    "        # Update best metrics if current accuracy is higher\n",
    "        if val_acc > best_metrics['accuracy']:\n",
    "            best_metrics.update({\n",
    "                'accuracy': val_acc,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "                'epoch': epoch,\n",
    "                'confusion_matrix': confusion_mat  # Store the current confusion matrix\n",
    "            })\n",
    "\n",
    "    # Print best metrics after training\n",
    "    print('Best validation results obtained at epoch {}:'.format(best_metrics['epoch']))\n",
    "    for metric, value in best_metrics.items():\n",
    "        if metric != 'epoch' and metric != 'confusion_matrix':  # We don't need to print the epoch again\n",
    "            print(f'{metric.capitalize()}: {value:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c13322-4be8-41a2-a624-4c5bedf2499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [1][10/33]\tBT 0.005 (0.426)\tDT 0.000 (0.203)\tloss 221.433 (125.052)\tAcc@1 53.125 (39.062)\n",
      "Train: [1][20/33]\tBT 0.004 (0.215)\tDT 0.000 (0.102)\tloss 161.360 (148.043)\tAcc@1 51.562 (44.922)\n",
      "Train: [1][30/33]\tBT 0.005 (0.145)\tDT 0.000 (0.068)\tloss 70.061 (131.127)\tAcc@1 32.812 (47.448)\n",
      "Train epoch 1, loss: 125.8565, accuracy: 47.50%\n",
      "Test: [0/13]\tTime 1.864 (1.864)\tLoss 148.8089 (148.8089)\tAcc@1 31.250 (31.250)\n",
      "Test: [10/13]\tTime 0.009 (0.180)\tLoss 124.1042 (150.4734)\tAcc@1 34.375 (25.284)\n",
      " * Acc@1 25.000 Precision: 0.062, Recall: 0.250, F1: 0.100\n",
      "Validation epoch 1: Loss: 150.7019, Accuracy: 25.00%, Precision: 0.062, Recall: 0.250, F1: 0.100, \n",
      "Train: [2][10/33]\tBT 0.010 (0.223)\tDT 0.000 (0.213)\tloss 16.611 (45.429)\tAcc@1 48.438 (57.188)\n",
      "Train: [2][20/33]\tBT 0.008 (0.164)\tDT 0.000 (0.154)\tloss 24.012 (38.345)\tAcc@1 50.000 (58.516)\n",
      "Train: [2][30/33]\tBT 0.010 (0.112)\tDT 0.002 (0.103)\tloss 47.402 (39.977)\tAcc@1 73.438 (61.458)\n",
      "Train epoch 2, loss: 39.2269, accuracy: 61.30%\n",
      "Test: [0/13]\tTime 1.940 (1.940)\tLoss 29.1850 (29.1850)\tAcc@1 57.812 (57.812)\n",
      "Test: [10/13]\tTime 0.004 (0.200)\tLoss 10.5592 (24.0447)\tAcc@1 78.125 (62.358)\n",
      " * Acc@1 61.298 Precision: 0.527, Recall: 0.613, F1: 0.550\n",
      "Validation epoch 2: Loss: 24.0661, Accuracy: 61.30%, Precision: 0.527, Recall: 0.613, F1: 0.550, \n",
      "Train: [3][10/33]\tBT 0.010 (0.219)\tDT 0.000 (0.207)\tloss 49.765 (28.197)\tAcc@1 35.938 (59.688)\n",
      "Train: [3][20/33]\tBT 0.008 (0.166)\tDT 0.000 (0.155)\tloss 35.839 (38.039)\tAcc@1 71.875 (60.312)\n",
      "Train: [3][30/33]\tBT 0.008 (0.113)\tDT 0.000 (0.104)\tloss 22.104 (37.551)\tAcc@1 64.062 (59.688)\n",
      "Train epoch 3, loss: 36.2621, accuracy: 60.67%\n",
      "Test: [0/13]\tTime 1.874 (1.874)\tLoss 51.1255 (51.1255)\tAcc@1 42.188 (42.188)\n",
      "Test: [10/13]\tTime 0.005 (0.210)\tLoss 50.5872 (47.5734)\tAcc@1 50.000 (45.881)\n",
      " * Acc@1 44.471 Precision: 0.358, Recall: 0.445, F1: 0.342\n",
      "Validation epoch 3: Loss: 48.1761, Accuracy: 44.47%, Precision: 0.358, Recall: 0.445, F1: 0.342, \n",
      "Train: [4][10/33]\tBT 0.010 (0.215)\tDT 0.000 (0.205)\tloss 15.698 (24.963)\tAcc@1 62.500 (60.156)\n",
      "Train: [4][20/33]\tBT 0.042 (0.165)\tDT 0.033 (0.156)\tloss 20.706 (23.355)\tAcc@1 75.000 (64.219)\n",
      "Train: [4][30/33]\tBT 0.008 (0.113)\tDT 0.000 (0.104)\tloss 43.834 (24.455)\tAcc@1 50.000 (65.052)\n",
      "Train epoch 4, loss: 23.5410, accuracy: 65.77%\n",
      "Test: [0/13]\tTime 1.785 (1.785)\tLoss 13.3431 (13.3431)\tAcc@1 48.438 (48.438)\n",
      "Test: [10/13]\tTime 0.008 (0.174)\tLoss 16.9177 (14.2347)\tAcc@1 32.812 (44.744)\n",
      " * Acc@1 46.154 Precision: 0.500, Recall: 0.462, F1: 0.362\n",
      "Validation epoch 4: Loss: 14.1902, Accuracy: 46.15%, Precision: 0.500, Recall: 0.462, F1: 0.362, \n",
      "Train: [5][10/33]\tBT 0.005 (0.238)\tDT 0.000 (0.212)\tloss 40.125 (19.927)\tAcc@1 57.812 (67.500)\n",
      "Train: [5][20/33]\tBT 0.005 (0.167)\tDT 0.000 (0.150)\tloss 31.446 (26.548)\tAcc@1 73.438 (65.703)\n",
      "Train: [5][30/33]\tBT 0.005 (0.113)\tDT 0.000 (0.100)\tloss 6.364 (28.221)\tAcc@1 87.500 (65.000)\n",
      "Train epoch 5, loss: 28.2459, accuracy: 64.04%\n",
      "Test: [0/13]\tTime 1.801 (1.801)\tLoss 47.5884 (47.5884)\tAcc@1 48.438 (48.438)\n",
      "Test: [10/13]\tTime 0.015 (0.177)\tLoss 37.1625 (63.1229)\tAcc@1 54.688 (50.284)\n",
      " * Acc@1 49.880 Precision: 0.504, Recall: 0.499, F1: 0.383\n",
      "Validation epoch 5: Loss: 62.0493, Accuracy: 49.88%, Precision: 0.504, Recall: 0.499, F1: 0.383, \n",
      "Train: [6][10/33]\tBT 0.009 (0.238)\tDT 0.000 (0.203)\tloss 22.459 (30.019)\tAcc@1 68.750 (66.250)\n",
      "Train: [6][20/33]\tBT 0.056 (0.169)\tDT 0.051 (0.147)\tloss 16.722 (34.425)\tAcc@1 79.688 (64.531)\n",
      "Train: [6][30/33]\tBT 0.004 (0.114)\tDT 0.000 (0.098)\tloss 21.042 (35.035)\tAcc@1 75.000 (64.167)\n",
      "Train epoch 6, loss: 33.1894, accuracy: 65.58%\n",
      "Test: [0/13]\tTime 1.779 (1.779)\tLoss 27.4539 (27.4539)\tAcc@1 60.938 (60.938)\n",
      "Test: [10/13]\tTime 0.008 (0.176)\tLoss 13.6041 (18.2369)\tAcc@1 65.625 (63.210)\n",
      " * Acc@1 62.260 Precision: 0.642, Recall: 0.623, F1: 0.588\n",
      "Validation epoch 6: Loss: 18.3030, Accuracy: 62.26%, Precision: 0.642, Recall: 0.623, F1: 0.588, \n",
      "Train: [7][10/33]\tBT 0.010 (0.242)\tDT 0.000 (0.203)\tloss 30.208 (23.074)\tAcc@1 67.188 (72.344)\n",
      "Train: [7][20/33]\tBT 0.006 (0.169)\tDT 0.000 (0.146)\tloss 5.582 (22.365)\tAcc@1 81.250 (70.156)\n",
      "Train: [7][30/33]\tBT 0.007 (0.115)\tDT 0.000 (0.097)\tloss 31.361 (20.807)\tAcc@1 53.125 (69.583)\n",
      "Train epoch 7, loss: 19.7946, accuracy: 70.53%\n",
      "Test: [0/13]\tTime 1.837 (1.837)\tLoss 39.2716 (39.2716)\tAcc@1 50.000 (50.000)\n",
      "Test: [10/13]\tTime 0.008 (0.177)\tLoss 31.0622 (36.7534)\tAcc@1 51.562 (47.869)\n",
      " * Acc@1 46.875 Precision: 0.305, Recall: 0.469, F1: 0.321\n",
      "Validation epoch 7: Loss: 37.9497, Accuracy: 46.88%, Precision: 0.305, Recall: 0.469, F1: 0.321, \n",
      "Train: [8][10/33]\tBT 0.010 (0.215)\tDT 0.000 (0.205)\tloss 12.975 (10.832)\tAcc@1 71.875 (79.375)\n",
      "Train: [8][20/33]\tBT 0.009 (0.163)\tDT 0.000 (0.154)\tloss 11.807 (12.413)\tAcc@1 67.188 (75.938)\n",
      "Train: [8][30/33]\tBT 0.008 (0.112)\tDT 0.000 (0.103)\tloss 11.472 (10.941)\tAcc@1 70.312 (77.031)\n",
      "Train epoch 8, loss: 12.6958, accuracy: 74.62%\n",
      "Test: [0/13]\tTime 1.888 (1.888)\tLoss 93.2146 (93.2146)\tAcc@1 39.062 (39.062)\n",
      "Test: [10/13]\tTime 0.004 (0.194)\tLoss 110.1273 (90.3231)\tAcc@1 31.250 (45.028)\n",
      " * Acc@1 46.394 Precision: 0.328, Recall: 0.464, F1: 0.351\n",
      "Validation epoch 8: Loss: 89.5674, Accuracy: 46.39%, Precision: 0.328, Recall: 0.464, F1: 0.351, \n",
      "Train: [9][10/33]\tBT 0.010 (0.212)\tDT 0.000 (0.201)\tloss 6.471 (31.675)\tAcc@1 73.438 (64.219)\n",
      "Train: [9][20/33]\tBT 0.010 (0.165)\tDT 0.000 (0.155)\tloss 55.324 (29.989)\tAcc@1 65.625 (65.078)\n",
      "Train: [9][30/33]\tBT 0.009 (0.113)\tDT 0.000 (0.103)\tloss 38.269 (31.608)\tAcc@1 65.625 (66.146)\n",
      "Train epoch 9, loss: 31.0606, accuracy: 65.77%\n",
      "Test: [0/13]\tTime 1.845 (1.845)\tLoss 27.4288 (27.4288)\tAcc@1 39.062 (39.062)\n",
      "Test: [10/13]\tTime 0.004 (0.193)\tLoss 37.9062 (29.6002)\tAcc@1 43.750 (42.614)\n",
      " * Acc@1 43.269 Precision: 0.457, Recall: 0.433, F1: 0.339\n",
      "Validation epoch 9: Loss: 28.5659, Accuracy: 43.27%, Precision: 0.457, Recall: 0.433, F1: 0.339, \n",
      "Train: [10][10/33]\tBT 0.010 (0.218)\tDT 0.000 (0.207)\tloss 13.177 (16.461)\tAcc@1 60.938 (69.062)\n",
      "Train: [10][20/33]\tBT 0.008 (0.166)\tDT 0.000 (0.156)\tloss 24.711 (16.231)\tAcc@1 60.938 (69.844)\n",
      "Train: [10][30/33]\tBT 0.008 (0.113)\tDT 0.000 (0.104)\tloss 48.967 (25.035)\tAcc@1 73.438 (71.302)\n",
      "Train epoch 10, loss: 25.2169, accuracy: 70.34%\n",
      "Test: [0/13]\tTime 1.910 (1.910)\tLoss 4.0389 (4.0389)\tAcc@1 81.250 (81.250)\n",
      "Test: [10/13]\tTime 0.004 (0.195)\tLoss 9.8080 (5.3720)\tAcc@1 64.062 (77.699)\n",
      " * Acc@1 76.803 Precision: 0.793, Recall: 0.768, F1: 0.771\n",
      "Validation epoch 10: Loss: 5.9212, Accuracy: 76.80%, Precision: 0.793, Recall: 0.768, F1: 0.771, \n",
      "Train: [11][10/33]\tBT 0.010 (0.213)\tDT 0.000 (0.202)\tloss 17.310 (23.286)\tAcc@1 84.375 (71.875)\n",
      "Train: [11][20/33]\tBT 0.010 (0.160)\tDT 0.000 (0.150)\tloss 3.528 (16.300)\tAcc@1 89.062 (74.297)\n",
      "Train: [11][30/33]\tBT 0.008 (0.111)\tDT 0.000 (0.102)\tloss 3.644 (13.628)\tAcc@1 87.500 (76.667)\n",
      "Train epoch 11, loss: 13.8972, accuracy: 75.19%\n",
      "Test: [0/13]\tTime 1.909 (1.909)\tLoss 46.6492 (46.6492)\tAcc@1 48.438 (48.438)\n",
      "Test: [10/13]\tTime 0.006 (0.191)\tLoss 49.6584 (54.4016)\tAcc@1 50.000 (44.886)\n",
      " * Acc@1 46.635 Precision: 0.277, Recall: 0.466, F1: 0.332\n",
      "Validation epoch 11: Loss: 52.1788, Accuracy: 46.63%, Precision: 0.277, Recall: 0.466, F1: 0.332, \n",
      "Train: [12][10/33]\tBT 0.010 (0.218)\tDT 0.000 (0.207)\tloss 14.672 (18.320)\tAcc@1 43.750 (70.469)\n",
      "Train: [12][20/33]\tBT 0.008 (0.164)\tDT 0.000 (0.154)\tloss 11.401 (29.958)\tAcc@1 81.250 (67.109)\n",
      "Train: [12][30/33]\tBT 0.030 (0.113)\tDT 0.022 (0.104)\tloss 3.518 (25.303)\tAcc@1 84.375 (70.208)\n",
      "Train epoch 12, loss: 24.4479, accuracy: 70.10%\n",
      "Test: [0/13]\tTime 1.850 (1.850)\tLoss 26.8078 (26.8078)\tAcc@1 60.938 (60.938)\n",
      "Test: [10/13]\tTime 0.004 (0.194)\tLoss 46.9404 (37.1128)\tAcc@1 40.625 (50.568)\n",
      " * Acc@1 48.317 Precision: 0.525, Recall: 0.483, F1: 0.351\n",
      "Validation epoch 12: Loss: 39.0389, Accuracy: 48.32%, Precision: 0.525, Recall: 0.483, F1: 0.351, \n",
      "Train: [13][10/33]\tBT 0.035 (0.208)\tDT 0.024 (0.197)\tloss 38.754 (24.017)\tAcc@1 79.688 (67.812)\n",
      "Train: [13][20/33]\tBT 0.009 (0.162)\tDT 0.000 (0.152)\tloss 32.524 (22.302)\tAcc@1 79.688 (70.156)\n",
      "Train: [13][30/33]\tBT 0.009 (0.111)\tDT 0.000 (0.101)\tloss 5.167 (19.721)\tAcc@1 84.375 (72.396)\n",
      "Train epoch 13, loss: 19.4317, accuracy: 72.16%\n",
      "Test: [0/13]\tTime 1.885 (1.885)\tLoss 24.9301 (24.9301)\tAcc@1 42.188 (42.188)\n",
      "Test: [10/13]\tTime 0.008 (0.181)\tLoss 19.6021 (18.9533)\tAcc@1 46.875 (50.568)\n",
      " * Acc@1 49.519 Precision: 0.522, Recall: 0.495, F1: 0.393\n",
      "Validation epoch 13: Loss: 18.8178, Accuracy: 49.52%, Precision: 0.522, Recall: 0.495, F1: 0.393, \n",
      "Train: [14][10/33]\tBT 0.010 (0.214)\tDT 0.000 (0.204)\tloss 13.359 (18.393)\tAcc@1 87.500 (69.688)\n",
      "Train: [14][20/33]\tBT 0.011 (0.162)\tDT 0.002 (0.152)\tloss 11.114 (16.711)\tAcc@1 85.938 (73.828)\n",
      "Train: [14][30/33]\tBT 0.009 (0.114)\tDT 0.000 (0.104)\tloss 31.053 (16.438)\tAcc@1 60.938 (73.385)\n",
      "Train epoch 14, loss: 16.8638, accuracy: 72.26%\n",
      "Test: [0/13]\tTime 1.807 (1.807)\tLoss 90.5069 (90.5069)\tAcc@1 64.062 (64.062)\n",
      "Test: [10/13]\tTime 0.008 (0.176)\tLoss 122.6041 (87.7339)\tAcc@1 48.438 (62.500)\n",
      " * Acc@1 60.577 Precision: 0.522, Recall: 0.606, F1: 0.538\n",
      "Validation epoch 14: Loss: 90.2385, Accuracy: 60.58%, Precision: 0.522, Recall: 0.606, F1: 0.538, \n",
      "Train: [15][10/33]\tBT 0.009 (0.230)\tDT 0.000 (0.200)\tloss 9.047 (37.441)\tAcc@1 92.188 (73.438)\n",
      "Train: [15][20/33]\tBT 0.005 (0.161)\tDT 0.000 (0.142)\tloss 9.712 (27.423)\tAcc@1 78.125 (74.688)\n",
      "Train: [15][30/33]\tBT 0.006 (0.111)\tDT 0.000 (0.097)\tloss 2.224 (25.691)\tAcc@1 93.750 (74.740)\n",
      "Train epoch 15, loss: 24.7353, accuracy: 74.33%\n",
      "Test: [0/13]\tTime 1.906 (1.906)\tLoss 30.0583 (30.0583)\tAcc@1 54.688 (54.688)\n",
      "Test: [10/13]\tTime 0.008 (0.182)\tLoss 17.5342 (29.5321)\tAcc@1 70.312 (58.523)\n",
      " * Acc@1 59.375 Precision: 0.583, Recall: 0.594, F1: 0.537\n",
      "Validation epoch 15: Loss: 28.7292, Accuracy: 59.38%, Precision: 0.583, Recall: 0.594, F1: 0.537, \n",
      "Train: [16][10/33]\tBT 0.008 (0.226)\tDT 0.000 (0.199)\tloss 3.698 (6.975)\tAcc@1 90.625 (80.000)\n",
      "Train: [16][20/33]\tBT 0.013 (0.161)\tDT 0.008 (0.144)\tloss 10.111 (8.054)\tAcc@1 64.062 (78.359)\n",
      "Train: [16][30/33]\tBT 0.004 (0.110)\tDT 0.000 (0.097)\tloss 11.318 (9.649)\tAcc@1 70.312 (76.042)\n",
      "Train epoch 16, loss: 9.7538, accuracy: 76.15%\n",
      "Test: [0/13]\tTime 1.894 (1.894)\tLoss 43.8682 (43.8682)\tAcc@1 34.375 (34.375)\n",
      "Test: [10/13]\tTime 0.008 (0.184)\tLoss 46.4805 (33.6841)\tAcc@1 34.375 (50.568)\n",
      " * Acc@1 51.683 Precision: 0.455, Recall: 0.517, F1: 0.406\n",
      "Validation epoch 16: Loss: 33.7005, Accuracy: 51.68%, Precision: 0.455, Recall: 0.517, F1: 0.406, \n",
      "Train: [17][10/33]\tBT 0.009 (0.215)\tDT 0.000 (0.206)\tloss 15.644 (15.561)\tAcc@1 54.688 (73.125)\n",
      "Train: [17][20/33]\tBT 0.008 (0.167)\tDT 0.000 (0.157)\tloss 8.821 (13.208)\tAcc@1 75.000 (76.016)\n",
      "Train: [17][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.105)\tloss 15.565 (14.419)\tAcc@1 89.062 (75.781)\n",
      "Train epoch 17, loss: 15.7713, accuracy: 75.62%\n",
      "Test: [0/13]\tTime 1.842 (1.842)\tLoss 70.2845 (70.2845)\tAcc@1 62.500 (62.500)\n",
      "Test: [10/13]\tTime 0.007 (0.208)\tLoss 61.9952 (85.6401)\tAcc@1 62.500 (54.545)\n",
      " * Acc@1 54.928 Precision: 0.543, Recall: 0.549, F1: 0.482\n",
      "Validation epoch 17: Loss: 87.9520, Accuracy: 54.93%, Precision: 0.543, Recall: 0.549, F1: 0.482, \n",
      "Train: [18][10/33]\tBT 0.010 (0.209)\tDT 0.000 (0.199)\tloss 9.875 (17.923)\tAcc@1 78.125 (73.125)\n",
      "Train: [18][20/33]\tBT 0.009 (0.162)\tDT 0.000 (0.152)\tloss 3.397 (14.257)\tAcc@1 89.062 (76.094)\n",
      "Train: [18][30/33]\tBT 0.009 (0.111)\tDT 0.000 (0.102)\tloss 7.582 (12.790)\tAcc@1 79.688 (75.990)\n",
      "Train epoch 18, loss: 12.6730, accuracy: 76.01%\n",
      "Test: [0/13]\tTime 1.867 (1.867)\tLoss 28.9565 (28.9565)\tAcc@1 48.438 (48.438)\n",
      "Test: [10/13]\tTime 0.008 (0.177)\tLoss 28.0399 (31.0998)\tAcc@1 54.688 (46.591)\n",
      " * Acc@1 47.356 Precision: 0.269, Recall: 0.474, F1: 0.326\n",
      "Validation epoch 18: Loss: 30.8472, Accuracy: 47.36%, Precision: 0.269, Recall: 0.474, F1: 0.326, \n",
      "Train: [19][10/33]\tBT 0.005 (0.228)\tDT 0.000 (0.199)\tloss 10.012 (11.310)\tAcc@1 70.312 (79.219)\n",
      "Train: [19][20/33]\tBT 0.005 (0.162)\tDT 0.000 (0.144)\tloss 6.822 (10.379)\tAcc@1 78.125 (78.750)\n",
      "Train: [19][30/33]\tBT 0.007 (0.111)\tDT 0.000 (0.097)\tloss 11.565 (9.735)\tAcc@1 79.688 (78.333)\n",
      "Train epoch 19, loss: 9.9286, accuracy: 77.69%\n",
      "Test: [0/13]\tTime 1.846 (1.846)\tLoss 10.9786 (10.9786)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.008 (0.177)\tLoss 16.3456 (17.0578)\tAcc@1 43.750 (47.159)\n",
      " * Acc@1 48.317 Precision: 0.587, Recall: 0.483, F1: 0.416\n",
      "Validation epoch 19: Loss: 16.6651, Accuracy: 48.32%, Precision: 0.587, Recall: 0.483, F1: 0.416, \n",
      "Train: [20][10/33]\tBT 0.009 (0.214)\tDT 0.000 (0.204)\tloss 4.116 (6.651)\tAcc@1 90.625 (78.438)\n",
      "Train: [20][20/33]\tBT 0.009 (0.165)\tDT 0.000 (0.155)\tloss 3.397 (9.519)\tAcc@1 85.938 (78.359)\n",
      "Train: [20][30/33]\tBT 0.009 (0.113)\tDT 0.000 (0.104)\tloss 5.526 (8.632)\tAcc@1 85.938 (78.750)\n",
      "Train epoch 20, loss: 8.3214, accuracy: 79.04%\n",
      "Test: [0/13]\tTime 1.844 (1.844)\tLoss 28.2025 (28.2025)\tAcc@1 35.938 (35.938)\n",
      "Test: [10/13]\tTime 0.043 (0.190)\tLoss 21.2906 (24.2361)\tAcc@1 50.000 (47.159)\n",
      " * Acc@1 47.716 Precision: 0.646, Recall: 0.477, F1: 0.366\n",
      "Validation epoch 20: Loss: 23.5027, Accuracy: 47.72%, Precision: 0.646, Recall: 0.477, F1: 0.366, \n",
      "Train: [21][10/33]\tBT 0.010 (0.213)\tDT 0.000 (0.203)\tloss 3.302 (8.253)\tAcc@1 90.625 (75.938)\n",
      "Train: [21][20/33]\tBT 0.009 (0.164)\tDT 0.000 (0.154)\tloss 24.358 (13.113)\tAcc@1 73.438 (73.750)\n",
      "Train: [21][30/33]\tBT 0.009 (0.112)\tDT 0.000 (0.103)\tloss 29.836 (13.895)\tAcc@1 46.875 (72.917)\n",
      "Train epoch 21, loss: 13.5879, accuracy: 73.41%\n",
      "Test: [0/13]\tTime 1.772 (1.772)\tLoss 19.1361 (19.1361)\tAcc@1 56.250 (56.250)\n",
      "Test: [10/13]\tTime 0.008 (0.175)\tLoss 26.0679 (27.1410)\tAcc@1 48.438 (49.006)\n",
      " * Acc@1 49.519 Precision: 0.457, Recall: 0.495, F1: 0.417\n",
      "Validation epoch 21: Loss: 25.9288, Accuracy: 49.52%, Precision: 0.457, Recall: 0.495, F1: 0.417, \n",
      "Train: [22][10/33]\tBT 0.009 (0.239)\tDT 0.000 (0.206)\tloss 3.841 (9.285)\tAcc@1 85.938 (76.875)\n",
      "Train: [22][20/33]\tBT 0.005 (0.167)\tDT 0.000 (0.146)\tloss 17.956 (9.019)\tAcc@1 75.000 (78.750)\n",
      "Train: [22][30/33]\tBT 0.005 (0.115)\tDT 0.000 (0.100)\tloss 23.457 (10.174)\tAcc@1 59.375 (77.969)\n",
      "Train epoch 22, loss: 11.2468, accuracy: 76.78%\n",
      "Test: [0/13]\tTime 1.894 (1.894)\tLoss 26.9342 (26.9342)\tAcc@1 50.000 (50.000)\n",
      "Test: [10/13]\tTime 0.008 (0.180)\tLoss 16.8014 (23.6412)\tAcc@1 65.625 (56.250)\n",
      " * Acc@1 56.971 Precision: 0.419, Recall: 0.570, F1: 0.469\n",
      "Validation epoch 22: Loss: 22.6847, Accuracy: 56.97%, Precision: 0.419, Recall: 0.570, F1: 0.469, \n",
      "Train: [23][10/33]\tBT 0.008 (0.230)\tDT 0.000 (0.196)\tloss 10.318 (13.395)\tAcc@1 79.688 (76.406)\n",
      "Train: [23][20/33]\tBT 0.005 (0.163)\tDT 0.000 (0.142)\tloss 21.220 (13.108)\tAcc@1 73.438 (75.781)\n",
      "Train: [23][30/33]\tBT 0.022 (0.111)\tDT 0.017 (0.095)\tloss 26.040 (15.411)\tAcc@1 78.125 (73.281)\n",
      "Train epoch 23, loss: 18.1047, accuracy: 72.60%\n",
      "Test: [0/13]\tTime 1.867 (1.867)\tLoss 36.0575 (36.0575)\tAcc@1 42.188 (42.188)\n",
      "Test: [10/13]\tTime 0.008 (0.177)\tLoss 55.8002 (41.1809)\tAcc@1 37.500 (45.170)\n",
      " * Acc@1 45.072 Precision: 0.328, Recall: 0.451, F1: 0.342\n",
      "Validation epoch 23: Loss: 41.9449, Accuracy: 45.07%, Precision: 0.328, Recall: 0.451, F1: 0.342, \n",
      "Train: [24][10/33]\tBT 0.010 (0.206)\tDT 0.000 (0.196)\tloss 30.571 (18.135)\tAcc@1 64.062 (71.719)\n",
      "Train: [24][20/33]\tBT 0.008 (0.164)\tDT 0.000 (0.155)\tloss 8.453 (16.169)\tAcc@1 71.875 (73.906)\n",
      "Train: [24][30/33]\tBT 0.008 (0.113)\tDT 0.000 (0.103)\tloss 16.102 (14.798)\tAcc@1 76.562 (75.208)\n",
      "Train epoch 24, loss: 14.5224, accuracy: 75.24%\n",
      "Test: [0/13]\tTime 1.919 (1.919)\tLoss 30.4768 (30.4768)\tAcc@1 45.312 (45.312)\n",
      "Test: [10/13]\tTime 0.004 (0.191)\tLoss 32.4035 (25.3747)\tAcc@1 51.562 (53.551)\n",
      " * Acc@1 54.688 Precision: 0.462, Recall: 0.547, F1: 0.476\n",
      "Validation epoch 24: Loss: 24.5968, Accuracy: 54.69%, Precision: 0.462, Recall: 0.547, F1: 0.476, \n",
      "Train: [25][10/33]\tBT 0.010 (0.221)\tDT 0.000 (0.211)\tloss 5.650 (11.890)\tAcc@1 75.000 (72.031)\n",
      "Train: [25][20/33]\tBT 0.009 (0.167)\tDT 0.000 (0.157)\tloss 14.552 (9.855)\tAcc@1 71.875 (77.266)\n",
      "Train: [25][30/33]\tBT 0.008 (0.115)\tDT 0.000 (0.106)\tloss 2.756 (10.275)\tAcc@1 90.625 (76.615)\n",
      "Train epoch 25, loss: 10.5692, accuracy: 77.21%\n",
      "Test: [0/13]\tTime 1.844 (1.844)\tLoss 49.5099 (49.5099)\tAcc@1 40.625 (40.625)\n",
      "Test: [10/13]\tTime 0.005 (0.186)\tLoss 41.2433 (52.7838)\tAcc@1 65.625 (46.591)\n",
      " * Acc@1 48.077 Precision: 0.469, Recall: 0.481, F1: 0.416\n",
      "Validation epoch 25: Loss: 52.2276, Accuracy: 48.08%, Precision: 0.469, Recall: 0.481, F1: 0.416, \n",
      "Train: [26][10/33]\tBT 0.010 (0.216)\tDT 0.000 (0.205)\tloss 15.785 (15.140)\tAcc@1 68.750 (76.875)\n",
      "Train: [26][20/33]\tBT 0.008 (0.167)\tDT 0.000 (0.157)\tloss 3.668 (11.988)\tAcc@1 85.938 (78.438)\n",
      "Train: [26][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.105)\tloss 10.351 (10.495)\tAcc@1 84.375 (78.594)\n",
      "Train epoch 26, loss: 10.2590, accuracy: 78.61%\n",
      "Test: [0/13]\tTime 1.924 (1.924)\tLoss 10.5204 (10.5204)\tAcc@1 73.438 (73.438)\n",
      "Test: [10/13]\tTime 0.004 (0.191)\tLoss 10.1526 (13.5265)\tAcc@1 68.750 (61.648)\n",
      " * Acc@1 60.938 Precision: 0.585, Recall: 0.609, F1: 0.528\n",
      "Validation epoch 26: Loss: 13.7985, Accuracy: 60.94%, Precision: 0.585, Recall: 0.609, F1: 0.528, \n",
      "Train: [27][10/33]\tBT 0.010 (0.217)\tDT 0.000 (0.206)\tloss 12.766 (6.325)\tAcc@1 62.500 (80.312)\n",
      "Train: [27][20/33]\tBT 0.008 (0.166)\tDT 0.000 (0.156)\tloss 13.852 (7.726)\tAcc@1 70.312 (79.922)\n",
      "Train: [27][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.104)\tloss 9.441 (6.993)\tAcc@1 79.688 (80.365)\n",
      "Train epoch 27, loss: 6.9445, accuracy: 80.05%\n",
      "Test: [0/13]\tTime 1.865 (1.865)\tLoss 20.1541 (20.1541)\tAcc@1 59.375 (59.375)\n",
      "Test: [10/13]\tTime 0.008 (0.179)\tLoss 24.0483 (24.9889)\tAcc@1 46.875 (50.568)\n",
      " * Acc@1 49.159 Precision: 0.515, Recall: 0.492, F1: 0.389\n",
      "Validation epoch 27: Loss: 25.9540, Accuracy: 49.16%, Precision: 0.515, Recall: 0.492, F1: 0.389, \n",
      "Train: [28][10/33]\tBT 0.005 (0.232)\tDT 0.000 (0.199)\tloss 3.542 (9.081)\tAcc@1 87.500 (79.531)\n",
      "Train: [28][20/33]\tBT 0.005 (0.163)\tDT 0.000 (0.143)\tloss 8.606 (7.386)\tAcc@1 71.875 (81.406)\n",
      "Train: [28][30/33]\tBT 0.004 (0.112)\tDT 0.000 (0.097)\tloss 9.540 (7.534)\tAcc@1 68.750 (80.417)\n",
      "Train epoch 28, loss: 7.5384, accuracy: 80.00%\n",
      "Test: [0/13]\tTime 1.834 (1.834)\tLoss 27.0797 (27.0797)\tAcc@1 48.438 (48.438)\n",
      "Test: [10/13]\tTime 0.008 (0.181)\tLoss 19.3826 (22.4354)\tAcc@1 51.562 (51.420)\n",
      " * Acc@1 50.481 Precision: 0.703, Recall: 0.505, F1: 0.409\n",
      "Validation epoch 28: Loss: 22.8738, Accuracy: 50.48%, Precision: 0.703, Recall: 0.505, F1: 0.409, \n",
      "Train: [29][10/33]\tBT 0.008 (0.239)\tDT 0.000 (0.208)\tloss 3.775 (5.800)\tAcc@1 81.250 (81.719)\n",
      "Train: [29][20/33]\tBT 0.036 (0.169)\tDT 0.031 (0.150)\tloss 5.501 (4.986)\tAcc@1 84.375 (83.672)\n",
      "Train: [29][30/33]\tBT 0.005 (0.114)\tDT 0.000 (0.100)\tloss 6.686 (6.256)\tAcc@1 79.688 (82.448)\n",
      "Train epoch 29, loss: 6.7942, accuracy: 81.73%\n",
      "Test: [0/13]\tTime 1.837 (1.837)\tLoss 37.7969 (37.7969)\tAcc@1 62.500 (62.500)\n",
      "Test: [10/13]\tTime 0.008 (0.178)\tLoss 53.7344 (35.9122)\tAcc@1 40.625 (58.097)\n",
      " * Acc@1 57.091 Precision: 0.510, Recall: 0.571, F1: 0.506\n",
      "Validation epoch 29: Loss: 35.8241, Accuracy: 57.09%, Precision: 0.510, Recall: 0.571, F1: 0.506, \n",
      "Train: [30][10/33]\tBT 0.041 (0.251)\tDT 0.000 (0.207)\tloss 10.337 (14.124)\tAcc@1 70.312 (75.156)\n",
      "Train: [30][20/33]\tBT 0.006 (0.166)\tDT 0.000 (0.141)\tloss 5.605 (15.018)\tAcc@1 85.938 (74.453)\n",
      "Train: [30][30/33]\tBT 0.004 (0.112)\tDT 0.000 (0.094)\tloss 8.534 (13.746)\tAcc@1 81.250 (74.792)\n",
      "Train epoch 30, loss: 13.2281, accuracy: 75.24%\n",
      "Test: [0/13]\tTime 1.705 (1.705)\tLoss 10.9336 (10.9336)\tAcc@1 62.500 (62.500)\n",
      "Test: [10/13]\tTime 0.008 (0.175)\tLoss 8.4106 (6.4317)\tAcc@1 64.062 (72.017)\n",
      " * Acc@1 72.476 Precision: 0.766, Recall: 0.725, F1: 0.715\n",
      "Validation epoch 30: Loss: 6.4670, Accuracy: 72.48%, Precision: 0.766, Recall: 0.725, F1: 0.715, \n",
      "Train: [31][10/33]\tBT 0.010 (0.226)\tDT 0.000 (0.216)\tloss 4.209 (5.020)\tAcc@1 82.812 (85.000)\n",
      "Train: [31][20/33]\tBT 0.008 (0.164)\tDT 0.000 (0.154)\tloss 19.718 (10.696)\tAcc@1 78.125 (79.531)\n",
      "Train: [31][30/33]\tBT 0.009 (0.112)\tDT 0.000 (0.103)\tloss 4.751 (14.545)\tAcc@1 78.125 (76.458)\n",
      "Train epoch 31, loss: 13.9792, accuracy: 77.02%\n",
      "Test: [0/13]\tTime 1.866 (1.866)\tLoss 11.5767 (11.5767)\tAcc@1 60.938 (60.938)\n",
      "Test: [10/13]\tTime 0.008 (0.177)\tLoss 13.3481 (10.8316)\tAcc@1 67.188 (66.761)\n",
      " * Acc@1 67.188 Precision: 0.785, Recall: 0.672, F1: 0.664\n",
      "Validation epoch 31: Loss: 10.5401, Accuracy: 67.19%, Precision: 0.785, Recall: 0.672, F1: 0.664, \n",
      "Train: [32][10/33]\tBT 0.010 (0.239)\tDT 0.000 (0.211)\tloss 6.623 (5.951)\tAcc@1 82.812 (83.125)\n",
      "Train: [32][20/33]\tBT 0.017 (0.167)\tDT 0.012 (0.150)\tloss 5.683 (6.077)\tAcc@1 82.812 (82.812)\n",
      "Train: [32][30/33]\tBT 0.004 (0.113)\tDT 0.000 (0.100)\tloss 2.179 (5.423)\tAcc@1 93.750 (83.438)\n",
      "Train epoch 32, loss: 5.1705, accuracy: 84.23%\n",
      "Test: [0/13]\tTime 1.830 (1.830)\tLoss 14.0061 (14.0061)\tAcc@1 60.938 (60.938)\n",
      "Test: [10/13]\tTime 0.008 (0.177)\tLoss 4.4585 (8.3027)\tAcc@1 75.000 (71.733)\n",
      " * Acc@1 72.356 Precision: 0.782, Recall: 0.724, F1: 0.710\n",
      "Validation epoch 32: Loss: 8.0505, Accuracy: 72.36%, Precision: 0.782, Recall: 0.724, F1: 0.710, \n",
      "Train: [33][10/33]\tBT 0.011 (0.212)\tDT 0.000 (0.202)\tloss 9.263 (8.158)\tAcc@1 79.688 (79.531)\n",
      "Train: [33][20/33]\tBT 0.009 (0.161)\tDT 0.000 (0.151)\tloss 8.536 (6.773)\tAcc@1 81.250 (81.250)\n",
      "Train: [33][30/33]\tBT 0.008 (0.110)\tDT 0.000 (0.101)\tloss 4.232 (6.843)\tAcc@1 87.500 (81.719)\n",
      "Train epoch 33, loss: 6.5634, accuracy: 82.36%\n",
      "Test: [0/13]\tTime 1.803 (1.803)\tLoss 13.3417 (13.3417)\tAcc@1 54.688 (54.688)\n",
      "Test: [10/13]\tTime 0.004 (0.191)\tLoss 14.3564 (13.5111)\tAcc@1 53.125 (53.125)\n",
      " * Acc@1 53.125 Precision: 0.617, Recall: 0.531, F1: 0.514\n",
      "Validation epoch 33: Loss: 13.2045, Accuracy: 53.13%, Precision: 0.617, Recall: 0.531, F1: 0.514, \n",
      "Train: [34][10/33]\tBT 0.010 (0.211)\tDT 0.000 (0.201)\tloss 4.515 (3.820)\tAcc@1 84.375 (86.719)\n",
      "Train: [34][20/33]\tBT 0.011 (0.162)\tDT 0.000 (0.152)\tloss 3.913 (3.746)\tAcc@1 78.125 (86.797)\n",
      "Train: [34][30/33]\tBT 0.009 (0.112)\tDT 0.000 (0.102)\tloss 5.179 (4.627)\tAcc@1 81.250 (84.792)\n",
      "Train epoch 34, loss: 5.0094, accuracy: 84.57%\n",
      "Test: [0/13]\tTime 1.830 (1.830)\tLoss 21.0227 (21.0227)\tAcc@1 57.812 (57.812)\n",
      "Test: [10/13]\tTime 0.006 (0.199)\tLoss 24.0211 (21.5667)\tAcc@1 54.688 (55.256)\n",
      " * Acc@1 56.010 Precision: 0.656, Recall: 0.560, F1: 0.467\n",
      "Validation epoch 34: Loss: 21.2388, Accuracy: 56.01%, Precision: 0.656, Recall: 0.560, F1: 0.467, \n",
      "Train: [35][10/33]\tBT 0.010 (0.218)\tDT 0.000 (0.207)\tloss 36.472 (14.362)\tAcc@1 34.375 (68.750)\n",
      "Train: [35][20/33]\tBT 0.008 (0.163)\tDT 0.000 (0.153)\tloss 34.896 (21.294)\tAcc@1 78.125 (68.359)\n",
      "Train: [35][30/33]\tBT 0.008 (0.111)\tDT 0.000 (0.102)\tloss 22.746 (24.207)\tAcc@1 62.500 (66.250)\n",
      "Train epoch 35, loss: 23.0111, accuracy: 67.50%\n",
      "Test: [0/13]\tTime 1.847 (1.847)\tLoss 17.4081 (17.4081)\tAcc@1 54.688 (54.688)\n",
      "Test: [10/13]\tTime 0.004 (0.198)\tLoss 23.8658 (23.8541)\tAcc@1 50.000 (51.278)\n",
      " * Acc@1 50.240 Precision: 0.717, Recall: 0.502, F1: 0.401\n",
      "Validation epoch 35: Loss: 24.1941, Accuracy: 50.24%, Precision: 0.717, Recall: 0.502, F1: 0.401, \n",
      "Train: [36][10/33]\tBT 0.009 (0.219)\tDT 0.000 (0.209)\tloss 9.499 (8.111)\tAcc@1 78.125 (81.250)\n",
      "Train: [36][20/33]\tBT 0.079 (0.172)\tDT 0.071 (0.162)\tloss 2.801 (7.261)\tAcc@1 90.625 (82.422)\n",
      "Train: [36][30/33]\tBT 0.008 (0.117)\tDT 0.000 (0.108)\tloss 4.546 (6.040)\tAcc@1 90.625 (84.167)\n",
      "Train epoch 36, loss: 6.0206, accuracy: 83.85%\n",
      "Test: [0/13]\tTime 1.840 (1.840)\tLoss 18.4385 (18.4385)\tAcc@1 59.375 (59.375)\n",
      "Test: [10/13]\tTime 0.004 (0.189)\tLoss 12.8483 (19.0435)\tAcc@1 64.062 (59.091)\n",
      " * Acc@1 59.375 Precision: 0.771, Recall: 0.594, F1: 0.532\n",
      "Validation epoch 36: Loss: 19.0291, Accuracy: 59.38%, Precision: 0.771, Recall: 0.594, F1: 0.532, \n",
      "Train: [37][10/33]\tBT 0.010 (0.211)\tDT 0.000 (0.200)\tloss 6.422 (9.304)\tAcc@1 81.250 (81.250)\n",
      "Train: [37][20/33]\tBT 0.009 (0.164)\tDT 0.000 (0.154)\tloss 8.696 (11.733)\tAcc@1 85.938 (76.797)\n",
      "Train: [37][30/33]\tBT 0.009 (0.113)\tDT 0.000 (0.103)\tloss 1.259 (10.398)\tAcc@1 93.750 (78.490)\n",
      "Train epoch 37, loss: 9.9920, accuracy: 78.80%\n",
      "Test: [0/13]\tTime 1.880 (1.880)\tLoss 10.7420 (10.7420)\tAcc@1 51.562 (51.562)\n",
      "Test: [10/13]\tTime 0.004 (0.193)\tLoss 10.6743 (12.0986)\tAcc@1 65.625 (57.386)\n",
      " * Acc@1 57.091 Precision: 0.655, Recall: 0.571, F1: 0.514\n",
      "Validation epoch 37: Loss: 12.3017, Accuracy: 57.09%, Precision: 0.655, Recall: 0.571, F1: 0.514, \n",
      "Train: [38][10/33]\tBT 0.010 (0.217)\tDT 0.000 (0.207)\tloss 10.732 (5.091)\tAcc@1 73.438 (84.062)\n",
      "Train: [38][20/33]\tBT 0.008 (0.165)\tDT 0.000 (0.156)\tloss 6.042 (5.019)\tAcc@1 85.938 (84.141)\n",
      "Train: [38][30/33]\tBT 0.008 (0.113)\tDT 0.000 (0.104)\tloss 3.598 (4.881)\tAcc@1 90.625 (84.740)\n",
      "Train epoch 38, loss: 5.1319, accuracy: 84.62%\n",
      "Test: [0/13]\tTime 1.884 (1.884)\tLoss 9.4659 (9.4659)\tAcc@1 54.688 (54.688)\n",
      "Test: [10/13]\tTime 0.004 (0.196)\tLoss 8.4854 (9.5804)\tAcc@1 65.625 (59.091)\n",
      " * Acc@1 58.894 Precision: 0.567, Recall: 0.589, F1: 0.538\n",
      "Validation epoch 38: Loss: 10.0167, Accuracy: 58.89%, Precision: 0.567, Recall: 0.589, F1: 0.538, \n",
      "Train: [39][10/33]\tBT 0.010 (0.214)\tDT 0.000 (0.204)\tloss 8.381 (3.966)\tAcc@1 73.438 (85.000)\n",
      "Train: [39][20/33]\tBT 0.008 (0.165)\tDT 0.000 (0.155)\tloss 3.682 (4.211)\tAcc@1 85.938 (85.234)\n",
      "Train: [39][30/33]\tBT 0.008 (0.113)\tDT 0.000 (0.104)\tloss 3.969 (4.647)\tAcc@1 82.812 (85.104)\n",
      "Train epoch 39, loss: 4.6756, accuracy: 85.19%\n",
      "Test: [0/13]\tTime 1.842 (1.842)\tLoss 7.9406 (7.9406)\tAcc@1 59.375 (59.375)\n",
      "Test: [10/13]\tTime 0.004 (0.189)\tLoss 13.5340 (11.1672)\tAcc@1 46.875 (58.523)\n",
      " * Acc@1 58.774 Precision: 0.698, Recall: 0.588, F1: 0.563\n",
      "Validation epoch 39: Loss: 10.9560, Accuracy: 58.77%, Precision: 0.698, Recall: 0.588, F1: 0.563, \n",
      "Train: [40][10/33]\tBT 0.010 (0.222)\tDT 0.000 (0.212)\tloss 6.506 (3.875)\tAcc@1 85.938 (86.094)\n",
      "Train: [40][20/33]\tBT 0.008 (0.166)\tDT 0.000 (0.157)\tloss 8.839 (4.362)\tAcc@1 79.688 (84.062)\n",
      "Train: [40][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.104)\tloss 5.038 (5.784)\tAcc@1 78.125 (82.604)\n",
      "Train epoch 40, loss: 5.7024, accuracy: 82.84%\n",
      "Test: [0/13]\tTime 1.970 (1.970)\tLoss 9.9054 (9.9054)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.004 (0.208)\tLoss 8.2383 (9.1680)\tAcc@1 62.500 (64.347)\n",
      " * Acc@1 64.423 Precision: 0.586, Recall: 0.644, F1: 0.577\n",
      "Validation epoch 40: Loss: 9.3033, Accuracy: 64.42%, Precision: 0.586, Recall: 0.644, F1: 0.577, \n",
      "Train: [41][10/33]\tBT 0.009 (0.212)\tDT 0.000 (0.202)\tloss 2.835 (3.838)\tAcc@1 90.625 (85.625)\n",
      "Train: [41][20/33]\tBT 0.009 (0.161)\tDT 0.000 (0.151)\tloss 3.425 (3.575)\tAcc@1 89.062 (86.328)\n",
      "Train: [41][30/33]\tBT 0.009 (0.111)\tDT 0.000 (0.101)\tloss 12.353 (4.435)\tAcc@1 75.000 (85.000)\n",
      "Train epoch 41, loss: 4.5694, accuracy: 84.62%\n",
      "Test: [0/13]\tTime 1.845 (1.845)\tLoss 25.8210 (25.8210)\tAcc@1 71.875 (71.875)\n",
      "Test: [10/13]\tTime 0.004 (0.185)\tLoss 37.3647 (27.0143)\tAcc@1 54.688 (66.477)\n",
      " * Acc@1 65.625 Precision: 0.587, Recall: 0.656, F1: 0.588\n",
      "Validation epoch 41: Loss: 26.8819, Accuracy: 65.62%, Precision: 0.587, Recall: 0.656, F1: 0.588, \n",
      "Train: [42][10/33]\tBT 0.012 (0.210)\tDT 0.000 (0.200)\tloss 4.734 (5.327)\tAcc@1 84.375 (84.062)\n",
      "Train: [42][20/33]\tBT 0.009 (0.161)\tDT 0.000 (0.151)\tloss 1.673 (5.243)\tAcc@1 96.875 (85.078)\n",
      "Train: [42][30/33]\tBT 0.009 (0.110)\tDT 0.000 (0.101)\tloss 12.217 (5.412)\tAcc@1 79.688 (84.010)\n",
      "Train epoch 42, loss: 5.1286, accuracy: 84.38%\n",
      "Test: [0/13]\tTime 1.814 (1.814)\tLoss 9.3466 (9.3466)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.008 (0.173)\tLoss 8.1589 (7.9336)\tAcc@1 73.438 (72.443)\n",
      " * Acc@1 71.394 Precision: 0.815, Recall: 0.714, F1: 0.718\n",
      "Validation epoch 42: Loss: 7.9619, Accuracy: 71.39%, Precision: 0.815, Recall: 0.714, F1: 0.718, \n",
      "Train: [43][10/33]\tBT 0.010 (0.213)\tDT 0.000 (0.203)\tloss 5.958 (3.931)\tAcc@1 76.562 (84.375)\n",
      "Train: [43][20/33]\tBT 0.008 (0.165)\tDT 0.000 (0.155)\tloss 7.204 (7.256)\tAcc@1 81.250 (81.406)\n",
      "Train: [43][30/33]\tBT 0.008 (0.112)\tDT 0.000 (0.103)\tloss 16.584 (7.595)\tAcc@1 71.875 (80.313)\n",
      "Train epoch 43, loss: 7.3357, accuracy: 80.77%\n",
      "Test: [0/13]\tTime 1.909 (1.909)\tLoss 7.2744 (7.2744)\tAcc@1 68.750 (68.750)\n",
      "Test: [10/13]\tTime 0.004 (0.195)\tLoss 6.0310 (6.0177)\tAcc@1 68.750 (70.739)\n",
      " * Acc@1 70.433 Precision: 0.732, Recall: 0.704, F1: 0.666\n",
      "Validation epoch 43: Loss: 6.2689, Accuracy: 70.43%, Precision: 0.732, Recall: 0.704, F1: 0.666, \n",
      "Train: [44][10/33]\tBT 0.009 (0.219)\tDT 0.000 (0.209)\tloss 0.686 (3.760)\tAcc@1 96.875 (85.156)\n",
      "Train: [44][20/33]\tBT 0.008 (0.171)\tDT 0.000 (0.161)\tloss 3.002 (3.850)\tAcc@1 93.750 (85.156)\n",
      "Train: [44][30/33]\tBT 0.008 (0.117)\tDT 0.000 (0.108)\tloss 5.399 (4.475)\tAcc@1 89.062 (84.115)\n",
      "Train epoch 44, loss: 4.5898, accuracy: 84.13%\n",
      "Test: [0/13]\tTime 1.802 (1.802)\tLoss 7.3316 (7.3316)\tAcc@1 76.562 (76.562)\n",
      "Test: [10/13]\tTime 0.005 (0.183)\tLoss 11.5909 (13.9534)\tAcc@1 67.188 (60.938)\n",
      " * Acc@1 61.418 Precision: 0.802, Recall: 0.614, F1: 0.561\n",
      "Validation epoch 44: Loss: 13.5242, Accuracy: 61.42%, Precision: 0.802, Recall: 0.614, F1: 0.561, \n",
      "Train: [45][10/33]\tBT 0.009 (0.223)\tDT 0.000 (0.212)\tloss 3.867 (11.241)\tAcc@1 84.375 (73.125)\n",
      "Train: [45][20/33]\tBT 0.008 (0.166)\tDT 0.000 (0.156)\tloss 8.037 (9.199)\tAcc@1 79.688 (77.344)\n",
      "Train: [45][30/33]\tBT 0.008 (0.113)\tDT 0.000 (0.104)\tloss 3.165 (7.707)\tAcc@1 85.938 (79.792)\n",
      "Train epoch 45, loss: 7.3157, accuracy: 80.72%\n",
      "Test: [0/13]\tTime 1.856 (1.856)\tLoss 13.1876 (13.1876)\tAcc@1 68.750 (68.750)\n",
      "Test: [10/13]\tTime 0.004 (0.185)\tLoss 6.1757 (14.3193)\tAcc@1 82.812 (65.767)\n",
      " * Acc@1 68.870 Precision: 0.651, Recall: 0.689, F1: 0.607\n",
      "Validation epoch 45: Loss: 12.6265, Accuracy: 68.87%, Precision: 0.651, Recall: 0.689, F1: 0.607, \n",
      "Train: [46][10/33]\tBT 0.009 (0.212)\tDT 0.000 (0.202)\tloss 5.823 (4.252)\tAcc@1 79.688 (85.312)\n",
      "Train: [46][20/33]\tBT 0.083 (0.167)\tDT 0.074 (0.157)\tloss 1.364 (4.002)\tAcc@1 92.188 (85.938)\n",
      "Train: [46][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.105)\tloss 11.750 (5.635)\tAcc@1 79.688 (82.031)\n",
      "Train epoch 46, loss: 5.8949, accuracy: 82.26%\n",
      "Test: [0/13]\tTime 1.869 (1.869)\tLoss 18.2419 (18.2419)\tAcc@1 54.688 (54.688)\n",
      "Test: [10/13]\tTime 0.004 (0.186)\tLoss 19.7832 (16.6093)\tAcc@1 62.500 (59.091)\n",
      " * Acc@1 60.457 Precision: 0.536, Recall: 0.605, F1: 0.520\n",
      "Validation epoch 46: Loss: 16.1618, Accuracy: 60.46%, Precision: 0.536, Recall: 0.605, F1: 0.520, \n",
      "Train: [47][10/33]\tBT 0.010 (0.214)\tDT 0.000 (0.204)\tloss 5.441 (6.054)\tAcc@1 84.375 (83.125)\n",
      "Train: [47][20/33]\tBT 0.008 (0.164)\tDT 0.000 (0.154)\tloss 3.074 (6.352)\tAcc@1 84.375 (82.969)\n",
      "Train: [47][30/33]\tBT 0.008 (0.112)\tDT 0.000 (0.103)\tloss 8.079 (6.269)\tAcc@1 78.125 (82.813)\n",
      "Train epoch 47, loss: 6.3722, accuracy: 82.84%\n",
      "Test: [0/13]\tTime 1.924 (1.924)\tLoss 15.3178 (15.3178)\tAcc@1 67.188 (67.188)\n",
      "Test: [10/13]\tTime 0.004 (0.204)\tLoss 16.7501 (19.0955)\tAcc@1 53.125 (53.693)\n",
      " * Acc@1 53.125 Precision: 0.823, Recall: 0.531, F1: 0.465\n",
      "Validation epoch 47: Loss: 19.2784, Accuracy: 53.13%, Precision: 0.823, Recall: 0.531, F1: 0.465, \n",
      "Train: [48][10/33]\tBT 0.010 (0.216)\tDT 0.000 (0.205)\tloss 3.287 (5.702)\tAcc@1 89.062 (81.562)\n",
      "Train: [48][20/33]\tBT 0.028 (0.167)\tDT 0.020 (0.157)\tloss 1.247 (3.952)\tAcc@1 93.750 (85.703)\n",
      "Train: [48][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.105)\tloss 2.911 (3.433)\tAcc@1 84.375 (87.135)\n",
      "Train epoch 48, loss: 3.5946, accuracy: 86.54%\n",
      "Test: [0/13]\tTime 1.905 (1.905)\tLoss 38.5545 (38.5545)\tAcc@1 51.562 (51.562)\n",
      "Test: [10/13]\tTime 0.004 (0.195)\tLoss 30.0957 (27.1937)\tAcc@1 51.562 (60.795)\n",
      " * Acc@1 58.654 Precision: 0.547, Recall: 0.587, F1: 0.503\n",
      "Validation epoch 48: Loss: 29.3652, Accuracy: 58.65%, Precision: 0.547, Recall: 0.587, F1: 0.503, \n",
      "Train: [49][10/33]\tBT 0.010 (0.225)\tDT 0.000 (0.215)\tloss 12.178 (8.181)\tAcc@1 62.500 (78.125)\n",
      "Train: [49][20/33]\tBT 0.009 (0.169)\tDT 0.000 (0.159)\tloss 4.476 (7.819)\tAcc@1 79.688 (78.750)\n",
      "Train: [49][30/33]\tBT 0.009 (0.115)\tDT 0.000 (0.106)\tloss 4.045 (6.478)\tAcc@1 89.062 (81.510)\n",
      "Train epoch 49, loss: 6.6480, accuracy: 81.11%\n",
      "Test: [0/13]\tTime 1.864 (1.864)\tLoss 32.7737 (32.7737)\tAcc@1 53.125 (53.125)\n",
      "Test: [10/13]\tTime 0.004 (0.197)\tLoss 34.8144 (37.2768)\tAcc@1 54.688 (47.159)\n",
      " * Acc@1 47.716 Precision: 0.313, Recall: 0.477, F1: 0.353\n",
      "Validation epoch 49: Loss: 36.5028, Accuracy: 47.72%, Precision: 0.313, Recall: 0.477, F1: 0.353, \n",
      "Train: [50][10/33]\tBT 0.010 (0.220)\tDT 0.000 (0.210)\tloss 7.706 (8.290)\tAcc@1 78.125 (80.156)\n",
      "Train: [50][20/33]\tBT 0.017 (0.164)\tDT 0.009 (0.154)\tloss 8.420 (6.423)\tAcc@1 71.875 (82.422)\n",
      "Train: [50][30/33]\tBT 0.008 (0.115)\tDT 0.000 (0.105)\tloss 6.835 (5.479)\tAcc@1 78.125 (83.906)\n",
      "Train epoch 50, loss: 5.4809, accuracy: 83.65%\n",
      "Test: [0/13]\tTime 1.808 (1.808)\tLoss 27.2496 (27.2496)\tAcc@1 60.938 (60.938)\n",
      "Test: [10/13]\tTime 0.004 (0.190)\tLoss 30.5188 (27.0598)\tAcc@1 59.375 (66.335)\n",
      " * Acc@1 65.144 Precision: 0.583, Recall: 0.651, F1: 0.585\n",
      "Validation epoch 50: Loss: 28.4771, Accuracy: 65.14%, Precision: 0.583, Recall: 0.651, F1: 0.585, \n",
      "Train: [51][10/33]\tBT 0.010 (0.222)\tDT 0.000 (0.211)\tloss 13.557 (18.785)\tAcc@1 89.062 (81.406)\n",
      "Train: [51][20/33]\tBT 0.008 (0.171)\tDT 0.000 (0.161)\tloss 9.363 (17.874)\tAcc@1 78.125 (78.359)\n",
      "Train: [51][30/33]\tBT 0.008 (0.117)\tDT 0.000 (0.108)\tloss 2.628 (13.929)\tAcc@1 92.188 (80.000)\n",
      "Train epoch 51, loss: 13.2694, accuracy: 80.14%\n",
      "Test: [0/13]\tTime 1.820 (1.820)\tLoss 9.4158 (9.4158)\tAcc@1 76.562 (76.562)\n",
      "Test: [10/13]\tTime 0.004 (0.195)\tLoss 23.5590 (18.5990)\tAcc@1 43.750 (56.818)\n",
      " * Acc@1 57.452 Precision: 0.595, Recall: 0.575, F1: 0.481\n",
      "Validation epoch 51: Loss: 18.0529, Accuracy: 57.45%, Precision: 0.595, Recall: 0.575, F1: 0.481, \n",
      "Train: [52][10/33]\tBT 0.012 (0.206)\tDT 0.000 (0.195)\tloss 5.668 (6.454)\tAcc@1 82.812 (86.094)\n",
      "Train: [52][20/33]\tBT 0.008 (0.159)\tDT 0.000 (0.149)\tloss 1.758 (4.439)\tAcc@1 85.938 (88.047)\n",
      "Train: [52][30/33]\tBT 0.008 (0.111)\tDT 0.000 (0.101)\tloss 1.990 (3.887)\tAcc@1 85.938 (88.385)\n",
      "Train epoch 52, loss: 3.7859, accuracy: 88.46%\n",
      "Test: [0/13]\tTime 1.760 (1.760)\tLoss 9.1556 (9.1556)\tAcc@1 78.125 (78.125)\n",
      "Test: [10/13]\tTime 0.009 (0.178)\tLoss 19.1016 (17.2110)\tAcc@1 70.312 (68.182)\n",
      " * Acc@1 67.188 Precision: 0.681, Recall: 0.672, F1: 0.599\n",
      "Validation epoch 52: Loss: 18.0892, Accuracy: 67.19%, Precision: 0.681, Recall: 0.672, F1: 0.599, \n",
      "Train: [53][10/33]\tBT 0.010 (0.244)\tDT 0.000 (0.206)\tloss 2.084 (4.989)\tAcc@1 90.625 (84.375)\n",
      "Train: [53][20/33]\tBT 0.005 (0.166)\tDT 0.000 (0.143)\tloss 4.958 (5.031)\tAcc@1 78.125 (83.125)\n",
      "Train: [53][30/33]\tBT 0.004 (0.113)\tDT 0.000 (0.097)\tloss 3.725 (4.446)\tAcc@1 87.500 (85.156)\n",
      "Train epoch 53, loss: 4.4930, accuracy: 85.00%\n",
      "Test: [0/13]\tTime 1.833 (1.833)\tLoss 40.7516 (40.7516)\tAcc@1 53.125 (53.125)\n",
      "Test: [10/13]\tTime 0.008 (0.180)\tLoss 29.6995 (34.0083)\tAcc@1 64.062 (57.670)\n",
      " * Acc@1 57.572 Precision: 0.494, Recall: 0.576, F1: 0.515\n",
      "Validation epoch 53: Loss: 34.7183, Accuracy: 57.57%, Precision: 0.494, Recall: 0.576, F1: 0.515, \n",
      "Train: [54][10/33]\tBT 0.006 (0.228)\tDT 0.000 (0.194)\tloss 33.764 (20.052)\tAcc@1 68.750 (76.406)\n",
      "Train: [54][20/33]\tBT 0.020 (0.162)\tDT 0.014 (0.141)\tloss 3.900 (19.874)\tAcc@1 81.250 (72.188)\n",
      "Train: [54][30/33]\tBT 0.005 (0.111)\tDT 0.000 (0.095)\tloss 2.347 (17.041)\tAcc@1 87.500 (74.531)\n",
      "Train epoch 54, loss: 16.6717, accuracy: 75.05%\n",
      "Test: [0/13]\tTime 1.842 (1.842)\tLoss 21.5557 (21.5557)\tAcc@1 64.062 (64.062)\n",
      "Test: [10/13]\tTime 0.009 (0.183)\tLoss 49.1682 (34.9097)\tAcc@1 40.625 (53.409)\n",
      " * Acc@1 53.125 Precision: 0.476, Recall: 0.531, F1: 0.467\n",
      "Validation epoch 54: Loss: 35.4065, Accuracy: 53.13%, Precision: 0.476, Recall: 0.531, F1: 0.467, \n",
      "Train: [55][10/33]\tBT 0.045 (0.235)\tDT 0.000 (0.201)\tloss 10.354 (9.204)\tAcc@1 65.625 (78.594)\n",
      "Train: [55][20/33]\tBT 0.005 (0.160)\tDT 0.000 (0.139)\tloss 4.952 (9.518)\tAcc@1 85.938 (78.125)\n",
      "Train: [55][30/33]\tBT 0.004 (0.112)\tDT 0.000 (0.096)\tloss 2.870 (9.339)\tAcc@1 76.562 (79.167)\n",
      "Train epoch 55, loss: 10.0341, accuracy: 78.70%\n",
      "Test: [0/13]\tTime 1.774 (1.774)\tLoss 46.0936 (46.0936)\tAcc@1 32.812 (32.812)\n",
      "Test: [10/13]\tTime 0.008 (0.172)\tLoss 32.7618 (33.5275)\tAcc@1 56.250 (49.574)\n",
      " * Acc@1 48.558 Precision: 0.577, Recall: 0.486, F1: 0.429\n",
      "Validation epoch 55: Loss: 34.6921, Accuracy: 48.56%, Precision: 0.577, Recall: 0.486, F1: 0.429, \n",
      "Train: [56][10/33]\tBT 0.010 (0.218)\tDT 0.000 (0.208)\tloss 20.963 (17.317)\tAcc@1 79.688 (70.625)\n",
      "Train: [56][20/33]\tBT 0.009 (0.166)\tDT 0.000 (0.156)\tloss 13.297 (16.801)\tAcc@1 71.875 (73.438)\n",
      "Train: [56][30/33]\tBT 0.009 (0.114)\tDT 0.000 (0.104)\tloss 29.825 (17.860)\tAcc@1 56.250 (71.354)\n",
      "Train epoch 56, loss: 17.1918, accuracy: 71.92%\n",
      "Test: [0/13]\tTime 1.855 (1.855)\tLoss 38.2237 (38.2237)\tAcc@1 42.188 (42.188)\n",
      "Test: [10/13]\tTime 0.004 (0.194)\tLoss 27.8297 (29.1917)\tAcc@1 51.562 (49.290)\n",
      " * Acc@1 49.639 Precision: 0.567, Recall: 0.496, F1: 0.378\n",
      "Validation epoch 56: Loss: 28.9013, Accuracy: 49.64%, Precision: 0.567, Recall: 0.496, F1: 0.378, \n",
      "Train: [57][10/33]\tBT 0.009 (0.209)\tDT 0.000 (0.199)\tloss 13.407 (22.871)\tAcc@1 82.812 (76.250)\n",
      "Train: [57][20/33]\tBT 0.010 (0.162)\tDT 0.000 (0.152)\tloss 2.939 (18.634)\tAcc@1 89.062 (74.141)\n",
      "Train: [57][30/33]\tBT 0.009 (0.112)\tDT 0.000 (0.102)\tloss 2.782 (14.158)\tAcc@1 90.625 (78.073)\n",
      "Train epoch 57, loss: 13.3674, accuracy: 78.85%\n",
      "Test: [0/13]\tTime 1.815 (1.815)\tLoss 16.7727 (16.7727)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.008 (0.173)\tLoss 13.9061 (14.3255)\tAcc@1 67.188 (69.460)\n",
      " * Acc@1 68.510 Precision: 0.779, Recall: 0.685, F1: 0.627\n",
      "Validation epoch 57: Loss: 14.6143, Accuracy: 68.51%, Precision: 0.779, Recall: 0.685, F1: 0.627, \n",
      "Train: [58][10/33]\tBT 0.005 (0.237)\tDT 0.000 (0.207)\tloss 8.016 (10.119)\tAcc@1 71.875 (78.750)\n",
      "Train: [58][20/33]\tBT 0.005 (0.168)\tDT 0.000 (0.149)\tloss 3.593 (7.940)\tAcc@1 87.500 (80.859)\n",
      "Train: [58][30/33]\tBT 0.005 (0.113)\tDT 0.000 (0.099)\tloss 1.240 (6.558)\tAcc@1 96.875 (83.438)\n",
      "Train epoch 58, loss: 6.6787, accuracy: 82.98%\n",
      "Test: [0/13]\tTime 1.750 (1.750)\tLoss 7.3505 (7.3505)\tAcc@1 68.750 (68.750)\n",
      "Test: [10/13]\tTime 0.008 (0.174)\tLoss 12.2913 (9.7665)\tAcc@1 43.750 (59.801)\n",
      " * Acc@1 60.337 Precision: 0.624, Recall: 0.603, F1: 0.522\n",
      "Validation epoch 58: Loss: 9.4749, Accuracy: 60.34%, Precision: 0.624, Recall: 0.603, F1: 0.522, \n",
      "Train: [59][10/33]\tBT 0.007 (0.227)\tDT 0.000 (0.194)\tloss 2.600 (2.740)\tAcc@1 92.188 (89.062)\n",
      "Train: [59][20/33]\tBT 0.012 (0.160)\tDT 0.000 (0.139)\tloss 14.968 (4.175)\tAcc@1 70.312 (86.719)\n",
      "Train: [59][30/33]\tBT 0.005 (0.112)\tDT 0.000 (0.096)\tloss 3.162 (4.249)\tAcc@1 84.375 (85.729)\n",
      "Train epoch 59, loss: 4.1825, accuracy: 85.67%\n",
      "Test: [0/13]\tTime 1.832 (1.832)\tLoss 7.9141 (7.9141)\tAcc@1 81.250 (81.250)\n",
      "Test: [10/13]\tTime 0.008 (0.174)\tLoss 10.6531 (10.8683)\tAcc@1 65.625 (67.188)\n",
      " * Acc@1 66.226 Precision: 0.780, Recall: 0.662, F1: 0.645\n",
      "Validation epoch 59: Loss: 11.3372, Accuracy: 66.23%, Precision: 0.780, Recall: 0.662, F1: 0.645, \n",
      "Train: [60][10/33]\tBT 0.009 (0.230)\tDT 0.000 (0.204)\tloss 3.212 (3.086)\tAcc@1 90.625 (88.281)\n",
      "Train: [60][20/33]\tBT 0.045 (0.161)\tDT 0.040 (0.144)\tloss 4.280 (3.117)\tAcc@1 92.188 (89.062)\n",
      "Train: [60][30/33]\tBT 0.005 (0.112)\tDT 0.000 (0.099)\tloss 3.981 (3.652)\tAcc@1 90.625 (88.438)\n",
      "Train epoch 60, loss: 3.9424, accuracy: 87.74%\n",
      "Test: [0/13]\tTime 1.795 (1.795)\tLoss 12.2194 (12.2194)\tAcc@1 60.938 (60.938)\n",
      "Test: [10/13]\tTime 0.009 (0.174)\tLoss 9.7960 (9.1232)\tAcc@1 64.062 (64.062)\n",
      " * Acc@1 63.702 Precision: 0.616, Recall: 0.637, F1: 0.596\n",
      "Validation epoch 60: Loss: 9.3447, Accuracy: 63.70%, Precision: 0.616, Recall: 0.637, F1: 0.596, \n",
      "Train: [61][10/33]\tBT 0.010 (0.210)\tDT 0.000 (0.199)\tloss 2.605 (3.089)\tAcc@1 92.188 (88.750)\n",
      "Train: [61][20/33]\tBT 0.010 (0.163)\tDT 0.000 (0.152)\tloss 3.154 (2.781)\tAcc@1 90.625 (90.156)\n",
      "Train: [61][30/33]\tBT 0.009 (0.111)\tDT 0.000 (0.102)\tloss 0.341 (2.571)\tAcc@1 93.750 (90.000)\n",
      "Train epoch 61, loss: 2.4694, accuracy: 90.29%\n",
      "Test: [0/13]\tTime 1.857 (1.857)\tLoss 9.4381 (9.4381)\tAcc@1 71.875 (71.875)\n",
      "Test: [10/13]\tTime 0.006 (0.188)\tLoss 8.5497 (7.0251)\tAcc@1 65.625 (71.875)\n",
      " * Acc@1 71.755 Precision: 0.747, Recall: 0.718, F1: 0.712\n",
      "Validation epoch 61: Loss: 6.7734, Accuracy: 71.75%, Precision: 0.747, Recall: 0.718, F1: 0.712, \n",
      "Train: [62][10/33]\tBT 0.010 (0.223)\tDT 0.000 (0.213)\tloss 5.768 (2.496)\tAcc@1 82.812 (91.250)\n",
      "Train: [62][20/33]\tBT 0.008 (0.163)\tDT 0.000 (0.153)\tloss 2.496 (2.585)\tAcc@1 90.625 (90.000)\n",
      "Train: [62][30/33]\tBT 0.071 (0.113)\tDT 0.063 (0.104)\tloss 1.034 (2.386)\tAcc@1 95.312 (90.573)\n",
      "Train epoch 62, loss: 2.5992, accuracy: 90.19%\n",
      "Test: [0/13]\tTime 1.890 (1.890)\tLoss 5.3881 (5.3881)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.004 (0.189)\tLoss 3.3204 (6.2252)\tAcc@1 85.938 (71.875)\n",
      " * Acc@1 72.115 Precision: 0.708, Recall: 0.721, F1: 0.688\n",
      "Validation epoch 62: Loss: 6.3990, Accuracy: 72.12%, Precision: 0.708, Recall: 0.721, F1: 0.688, \n",
      "Train: [63][10/33]\tBT 0.010 (0.219)\tDT 0.000 (0.208)\tloss 2.480 (2.506)\tAcc@1 87.500 (87.812)\n",
      "Train: [63][20/33]\tBT 0.008 (0.167)\tDT 0.000 (0.157)\tloss 1.932 (2.579)\tAcc@1 89.062 (88.047)\n",
      "Train: [63][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.105)\tloss 4.988 (2.591)\tAcc@1 78.125 (88.385)\n",
      "Train epoch 63, loss: 2.6971, accuracy: 88.37%\n",
      "Test: [0/13]\tTime 1.890 (1.890)\tLoss 3.0101 (3.0101)\tAcc@1 79.688 (79.688)\n",
      "Test: [10/13]\tTime 0.004 (0.201)\tLoss 7.0545 (6.8538)\tAcc@1 68.750 (73.438)\n",
      " * Acc@1 72.716 Precision: 0.725, Recall: 0.727, F1: 0.686\n",
      "Validation epoch 63: Loss: 7.1251, Accuracy: 72.72%, Precision: 0.725, Recall: 0.727, F1: 0.686, \n",
      "Train: [64][10/33]\tBT 0.010 (0.213)\tDT 0.000 (0.202)\tloss 2.563 (1.714)\tAcc@1 90.625 (91.719)\n",
      "Train: [64][20/33]\tBT 0.009 (0.164)\tDT 0.000 (0.153)\tloss 2.133 (2.021)\tAcc@1 92.188 (91.484)\n",
      "Train: [64][30/33]\tBT 0.009 (0.114)\tDT 0.000 (0.104)\tloss 1.631 (2.036)\tAcc@1 90.625 (91.406)\n",
      "Train epoch 64, loss: 2.1208, accuracy: 91.15%\n",
      "Test: [0/13]\tTime 1.820 (1.820)\tLoss 5.5589 (5.5589)\tAcc@1 79.688 (79.688)\n",
      "Test: [10/13]\tTime 0.004 (0.192)\tLoss 2.9021 (4.6234)\tAcc@1 81.250 (77.841)\n",
      " * Acc@1 76.442 Precision: 0.760, Recall: 0.764, F1: 0.756\n",
      "Validation epoch 64: Loss: 4.6687, Accuracy: 76.44%, Precision: 0.760, Recall: 0.764, F1: 0.756, \n",
      "Train: [65][10/33]\tBT 0.010 (0.215)\tDT 0.000 (0.205)\tloss 0.711 (1.793)\tAcc@1 96.875 (92.812)\n",
      "Train: [65][20/33]\tBT 0.016 (0.163)\tDT 0.008 (0.153)\tloss 1.730 (2.339)\tAcc@1 96.875 (91.016)\n",
      "Train: [65][30/33]\tBT 0.008 (0.111)\tDT 0.000 (0.102)\tloss 1.778 (2.270)\tAcc@1 89.062 (90.938)\n",
      "Train epoch 65, loss: 2.2625, accuracy: 90.67%\n",
      "Test: [0/13]\tTime 1.926 (1.926)\tLoss 10.7183 (10.7183)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.004 (0.192)\tLoss 13.3255 (13.0121)\tAcc@1 65.625 (65.341)\n",
      " * Acc@1 66.707 Precision: 0.699, Recall: 0.667, F1: 0.605\n",
      "Validation epoch 65: Loss: 12.3892, Accuracy: 66.71%, Precision: 0.699, Recall: 0.667, F1: 0.605, \n",
      "Train: [66][10/33]\tBT 0.009 (0.212)\tDT 0.000 (0.202)\tloss 1.883 (2.950)\tAcc@1 90.625 (88.125)\n",
      "Train: [66][20/33]\tBT 0.008 (0.161)\tDT 0.000 (0.152)\tloss 5.080 (2.741)\tAcc@1 81.250 (89.062)\n",
      "Train: [66][30/33]\tBT 0.008 (0.110)\tDT 0.000 (0.101)\tloss 0.975 (2.498)\tAcc@1 93.750 (89.115)\n",
      "Train epoch 66, loss: 2.5519, accuracy: 89.28%\n",
      "Test: [0/13]\tTime 1.866 (1.866)\tLoss 6.4256 (6.4256)\tAcc@1 64.062 (64.062)\n",
      "Test: [10/13]\tTime 0.004 (0.195)\tLoss 2.8691 (6.0046)\tAcc@1 76.562 (70.312)\n",
      " * Acc@1 69.471 Precision: 0.674, Recall: 0.695, F1: 0.669\n",
      "Validation epoch 66: Loss: 5.9995, Accuracy: 69.47%, Precision: 0.674, Recall: 0.695, F1: 0.669, \n",
      "Train: [67][10/33]\tBT 0.009 (0.213)\tDT 0.000 (0.202)\tloss 0.295 (2.260)\tAcc@1 96.875 (91.562)\n",
      "Train: [67][20/33]\tBT 0.009 (0.163)\tDT 0.000 (0.154)\tloss 1.754 (2.121)\tAcc@1 92.188 (91.406)\n",
      "Train: [67][30/33]\tBT 0.008 (0.112)\tDT 0.000 (0.103)\tloss 1.147 (1.762)\tAcc@1 90.625 (92.135)\n",
      "Train epoch 67, loss: 1.7906, accuracy: 92.21%\n",
      "Test: [0/13]\tTime 1.859 (1.859)\tLoss 7.7153 (7.7153)\tAcc@1 64.062 (64.062)\n",
      "Test: [10/13]\tTime 0.004 (0.193)\tLoss 3.4359 (8.3750)\tAcc@1 82.812 (69.176)\n",
      " * Acc@1 70.192 Precision: 0.682, Recall: 0.702, F1: 0.651\n",
      "Validation epoch 67: Loss: 7.9864, Accuracy: 70.19%, Precision: 0.682, Recall: 0.702, F1: 0.651, \n",
      "Train: [68][10/33]\tBT 0.010 (0.222)\tDT 0.000 (0.212)\tloss 2.613 (1.150)\tAcc@1 87.500 (92.969)\n",
      "Train: [68][20/33]\tBT 0.008 (0.165)\tDT 0.000 (0.155)\tloss 0.124 (1.456)\tAcc@1 96.875 (93.203)\n",
      "Train: [68][30/33]\tBT 0.008 (0.112)\tDT 0.000 (0.103)\tloss 5.208 (1.589)\tAcc@1 81.250 (92.500)\n",
      "Train epoch 68, loss: 1.5643, accuracy: 92.50%\n",
      "Test: [0/13]\tTime 1.845 (1.845)\tLoss 5.5068 (5.5068)\tAcc@1 78.125 (78.125)\n",
      "Test: [10/13]\tTime 0.004 (0.188)\tLoss 11.4819 (9.0139)\tAcc@1 65.625 (69.318)\n",
      " * Acc@1 69.111 Precision: 0.641, Recall: 0.691, F1: 0.612\n",
      "Validation epoch 68: Loss: 9.1762, Accuracy: 69.11%, Precision: 0.641, Recall: 0.691, F1: 0.612, \n",
      "Train: [69][10/33]\tBT 0.010 (0.221)\tDT 0.000 (0.210)\tloss 2.513 (2.665)\tAcc@1 84.375 (88.750)\n",
      "Train: [69][20/33]\tBT 0.008 (0.168)\tDT 0.000 (0.158)\tloss 2.836 (2.732)\tAcc@1 87.500 (89.219)\n",
      "Train: [69][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.105)\tloss 0.467 (2.484)\tAcc@1 93.750 (89.740)\n",
      "Train epoch 69, loss: 2.5220, accuracy: 89.71%\n",
      "Test: [0/13]\tTime 1.901 (1.901)\tLoss 7.2071 (7.2071)\tAcc@1 64.062 (64.062)\n",
      "Test: [10/13]\tTime 0.006 (0.191)\tLoss 10.3790 (7.3962)\tAcc@1 62.500 (65.909)\n",
      " * Acc@1 67.788 Precision: 0.658, Recall: 0.678, F1: 0.644\n",
      "Validation epoch 69: Loss: 6.9102, Accuracy: 67.79%, Precision: 0.658, Recall: 0.678, F1: 0.644, \n",
      "Train: [70][10/33]\tBT 0.010 (0.207)\tDT 0.000 (0.197)\tloss 1.507 (1.738)\tAcc@1 93.750 (90.938)\n",
      "Train: [70][20/33]\tBT 0.009 (0.161)\tDT 0.000 (0.151)\tloss 0.421 (1.617)\tAcc@1 95.312 (91.250)\n",
      "Train: [70][30/33]\tBT 0.009 (0.113)\tDT 0.000 (0.103)\tloss 3.706 (2.022)\tAcc@1 87.500 (91.146)\n",
      "Train epoch 70, loss: 2.1034, accuracy: 90.77%\n",
      "Test: [0/13]\tTime 1.857 (1.857)\tLoss 8.6198 (8.6198)\tAcc@1 68.750 (68.750)\n",
      "Test: [10/13]\tTime 0.004 (0.194)\tLoss 9.5157 (7.9947)\tAcc@1 67.188 (72.727)\n",
      " * Acc@1 71.394 Precision: 0.748, Recall: 0.714, F1: 0.686\n",
      "Validation epoch 70: Loss: 8.4432, Accuracy: 71.39%, Precision: 0.748, Recall: 0.714, F1: 0.686, \n",
      "Train: [71][10/33]\tBT 0.009 (0.216)\tDT 0.000 (0.205)\tloss 3.193 (2.752)\tAcc@1 82.812 (89.688)\n",
      "Train: [71][20/33]\tBT 0.008 (0.163)\tDT 0.000 (0.153)\tloss 2.202 (2.139)\tAcc@1 92.188 (90.781)\n",
      "Train: [71][30/33]\tBT 0.008 (0.112)\tDT 0.000 (0.102)\tloss 2.788 (2.065)\tAcc@1 92.188 (91.198)\n",
      "Train epoch 71, loss: 2.1084, accuracy: 91.25%\n",
      "Test: [0/13]\tTime 1.859 (1.859)\tLoss 6.2805 (6.2805)\tAcc@1 71.875 (71.875)\n",
      "Test: [10/13]\tTime 0.004 (0.192)\tLoss 7.1443 (6.4207)\tAcc@1 71.875 (72.443)\n",
      " * Acc@1 71.635 Precision: 0.744, Recall: 0.716, F1: 0.699\n",
      "Validation epoch 71: Loss: 6.6686, Accuracy: 71.63%, Precision: 0.744, Recall: 0.716, F1: 0.699, \n",
      "Train: [72][10/33]\tBT 0.010 (0.211)\tDT 0.000 (0.201)\tloss 0.077 (1.825)\tAcc@1 98.438 (90.938)\n",
      "Train: [72][20/33]\tBT 0.052 (0.161)\tDT 0.042 (0.151)\tloss 0.815 (1.893)\tAcc@1 90.625 (90.938)\n",
      "Train: [72][30/33]\tBT 0.008 (0.111)\tDT 0.000 (0.102)\tloss 1.239 (1.788)\tAcc@1 93.750 (91.771)\n",
      "Train epoch 72, loss: 1.7753, accuracy: 92.02%\n",
      "Test: [0/13]\tTime 1.867 (1.867)\tLoss 12.4998 (12.4998)\tAcc@1 60.938 (60.938)\n",
      "Test: [10/13]\tTime 0.004 (0.197)\tLoss 10.1670 (9.1703)\tAcc@1 71.875 (71.591)\n",
      " * Acc@1 71.635 Precision: 0.728, Recall: 0.716, F1: 0.671\n",
      "Validation epoch 72: Loss: 9.2658, Accuracy: 71.63%, Precision: 0.728, Recall: 0.716, F1: 0.671, \n",
      "Train: [73][10/33]\tBT 0.010 (0.210)\tDT 0.000 (0.200)\tloss 2.118 (1.842)\tAcc@1 95.312 (92.344)\n",
      "Train: [73][20/33]\tBT 0.009 (0.158)\tDT 0.000 (0.148)\tloss 3.452 (1.920)\tAcc@1 85.938 (91.094)\n",
      "Train: [73][30/33]\tBT 0.009 (0.111)\tDT 0.000 (0.101)\tloss 0.644 (1.841)\tAcc@1 95.312 (90.885)\n",
      "Train epoch 73, loss: 1.7439, accuracy: 91.25%\n",
      "Test: [0/13]\tTime 1.848 (1.848)\tLoss 5.0740 (5.0740)\tAcc@1 68.750 (68.750)\n",
      "Test: [10/13]\tTime 0.008 (0.177)\tLoss 6.2847 (7.1161)\tAcc@1 78.125 (71.023)\n",
      " * Acc@1 70.913 Precision: 0.702, Recall: 0.709, F1: 0.668\n",
      "Validation epoch 73: Loss: 7.0772, Accuracy: 70.91%, Precision: 0.702, Recall: 0.709, F1: 0.668, \n",
      "Train: [74][10/33]\tBT 0.009 (0.206)\tDT 0.000 (0.195)\tloss 0.102 (2.070)\tAcc@1 98.438 (90.312)\n",
      "Train: [74][20/33]\tBT 0.008 (0.159)\tDT 0.000 (0.149)\tloss 1.437 (1.918)\tAcc@1 92.188 (91.484)\n",
      "Train: [74][30/33]\tBT 0.008 (0.110)\tDT 0.000 (0.101)\tloss 0.252 (1.799)\tAcc@1 93.750 (91.094)\n",
      "Train epoch 74, loss: 1.7849, accuracy: 91.30%\n",
      "Test: [0/13]\tTime 1.933 (1.933)\tLoss 7.7287 (7.7287)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.004 (0.202)\tLoss 6.3050 (6.0981)\tAcc@1 71.875 (72.301)\n",
      " * Acc@1 71.514 Precision: 0.730, Recall: 0.715, F1: 0.696\n",
      "Validation epoch 74: Loss: 6.0988, Accuracy: 71.51%, Precision: 0.730, Recall: 0.715, F1: 0.696, \n",
      "Train: [75][10/33]\tBT 0.010 (0.219)\tDT 0.000 (0.209)\tloss 1.583 (1.229)\tAcc@1 96.875 (94.062)\n",
      "Train: [75][20/33]\tBT 0.024 (0.162)\tDT 0.015 (0.152)\tloss 1.689 (1.655)\tAcc@1 89.062 (92.500)\n",
      "Train: [75][30/33]\tBT 0.008 (0.111)\tDT 0.000 (0.102)\tloss 0.382 (1.602)\tAcc@1 96.875 (92.604)\n",
      "Train epoch 75, loss: 1.5571, accuracy: 92.45%\n",
      "Test: [0/13]\tTime 1.815 (1.815)\tLoss 14.2615 (14.2615)\tAcc@1 59.375 (59.375)\n",
      "Test: [10/13]\tTime 0.008 (0.175)\tLoss 12.3375 (11.6393)\tAcc@1 67.188 (66.761)\n",
      " * Acc@1 67.788 Precision: 0.709, Recall: 0.678, F1: 0.623\n",
      "Validation epoch 75: Loss: 11.5598, Accuracy: 67.79%, Precision: 0.709, Recall: 0.678, F1: 0.623, \n",
      "Train: [76][10/33]\tBT 0.009 (0.234)\tDT 0.000 (0.194)\tloss 2.287 (1.674)\tAcc@1 90.625 (92.656)\n",
      "Train: [76][20/33]\tBT 0.019 (0.159)\tDT 0.012 (0.135)\tloss 1.236 (1.587)\tAcc@1 81.250 (92.188)\n",
      "Train: [76][30/33]\tBT 0.005 (0.108)\tDT 0.000 (0.090)\tloss 0.596 (1.496)\tAcc@1 95.312 (92.135)\n",
      "Train epoch 76, loss: 1.5233, accuracy: 92.26%\n",
      "Test: [0/13]\tTime 1.874 (1.874)\tLoss 9.8121 (9.8121)\tAcc@1 75.000 (75.000)\n",
      "Test: [10/13]\tTime 0.008 (0.178)\tLoss 4.3407 (9.1977)\tAcc@1 84.375 (71.307)\n",
      " * Acc@1 71.274 Precision: 0.699, Recall: 0.713, F1: 0.645\n",
      "Validation epoch 76: Loss: 9.1946, Accuracy: 71.27%, Precision: 0.699, Recall: 0.713, F1: 0.645, \n",
      "Train: [77][10/33]\tBT 0.009 (0.225)\tDT 0.000 (0.198)\tloss 1.977 (1.391)\tAcc@1 95.312 (93.281)\n",
      "Train: [77][20/33]\tBT 0.005 (0.166)\tDT 0.000 (0.149)\tloss 0.869 (1.170)\tAcc@1 95.312 (93.203)\n",
      "Train: [77][30/33]\tBT 0.005 (0.112)\tDT 0.000 (0.099)\tloss 2.666 (1.345)\tAcc@1 92.188 (93.177)\n",
      "Train epoch 77, loss: 1.3246, accuracy: 93.12%\n",
      "Test: [0/13]\tTime 1.836 (1.836)\tLoss 3.1884 (3.1884)\tAcc@1 85.938 (85.938)\n",
      "Test: [10/13]\tTime 0.008 (0.180)\tLoss 8.9082 (9.7577)\tAcc@1 75.000 (71.165)\n",
      " * Acc@1 71.755 Precision: 0.694, Recall: 0.718, F1: 0.653\n",
      "Validation epoch 77: Loss: 9.5497, Accuracy: 71.75%, Precision: 0.694, Recall: 0.718, F1: 0.653, \n",
      "Train: [78][10/33]\tBT 0.033 (0.237)\tDT 0.000 (0.206)\tloss 1.048 (1.280)\tAcc@1 93.750 (94.844)\n",
      "Train: [78][20/33]\tBT 0.008 (0.161)\tDT 0.000 (0.143)\tloss 0.980 (1.529)\tAcc@1 92.188 (93.750)\n",
      "Train: [78][30/33]\tBT 0.007 (0.111)\tDT 0.000 (0.097)\tloss 1.304 (1.415)\tAcc@1 93.750 (93.750)\n",
      "Train epoch 78, loss: 1.3825, accuracy: 93.75%\n",
      "Test: [0/13]\tTime 1.796 (1.796)\tLoss 6.4871 (6.4871)\tAcc@1 78.125 (78.125)\n",
      "Test: [10/13]\tTime 0.008 (0.179)\tLoss 13.8596 (8.6086)\tAcc@1 67.188 (72.727)\n",
      " * Acc@1 71.995 Precision: 0.708, Recall: 0.720, F1: 0.661\n",
      "Validation epoch 78: Loss: 8.4397, Accuracy: 72.00%, Precision: 0.708, Recall: 0.720, F1: 0.661, \n",
      "Train: [79][10/33]\tBT 0.009 (0.233)\tDT 0.000 (0.198)\tloss 1.945 (1.759)\tAcc@1 85.938 (92.344)\n",
      "Train: [79][20/33]\tBT 0.005 (0.164)\tDT 0.000 (0.143)\tloss 1.630 (1.436)\tAcc@1 90.625 (93.125)\n",
      "Train: [79][30/33]\tBT 0.004 (0.111)\tDT 0.000 (0.095)\tloss 0.684 (1.573)\tAcc@1 93.750 (93.177)\n",
      "Train epoch 79, loss: 1.6203, accuracy: 93.08%\n",
      "Test: [0/13]\tTime 1.846 (1.846)\tLoss 8.3536 (8.3536)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.008 (0.183)\tLoss 6.2929 (6.3762)\tAcc@1 73.438 (74.006)\n",
      " * Acc@1 73.438 Precision: 0.718, Recall: 0.734, F1: 0.697\n",
      "Validation epoch 79: Loss: 6.4716, Accuracy: 73.44%, Precision: 0.718, Recall: 0.734, F1: 0.697, \n",
      "Train: [80][10/33]\tBT 0.008 (0.231)\tDT 0.000 (0.198)\tloss 0.460 (1.132)\tAcc@1 92.188 (91.406)\n",
      "Train: [80][20/33]\tBT 0.006 (0.162)\tDT 0.000 (0.141)\tloss 2.628 (1.390)\tAcc@1 93.750 (92.031)\n",
      "Train: [80][30/33]\tBT 0.005 (0.111)\tDT 0.000 (0.096)\tloss 0.847 (1.248)\tAcc@1 92.188 (92.813)\n",
      "Train epoch 80, loss: 1.2902, accuracy: 92.79%\n",
      "Test: [0/13]\tTime 1.838 (1.838)\tLoss 9.9291 (9.9291)\tAcc@1 67.188 (67.188)\n",
      "Test: [10/13]\tTime 0.008 (0.179)\tLoss 5.8099 (8.6228)\tAcc@1 75.000 (71.591)\n",
      " * Acc@1 71.514 Precision: 0.712, Recall: 0.715, F1: 0.661\n",
      "Validation epoch 80: Loss: 8.9277, Accuracy: 71.51%, Precision: 0.712, Recall: 0.715, F1: 0.661, \n",
      "Train: [81][10/33]\tBT 0.044 (0.240)\tDT 0.000 (0.202)\tloss 1.573 (1.501)\tAcc@1 93.750 (93.594)\n",
      "Train: [81][20/33]\tBT 0.005 (0.165)\tDT 0.000 (0.141)\tloss 2.037 (1.674)\tAcc@1 92.188 (92.578)\n",
      "Train: [81][30/33]\tBT 0.004 (0.111)\tDT 0.000 (0.094)\tloss 1.042 (1.663)\tAcc@1 95.312 (92.031)\n",
      "Train epoch 81, loss: 1.6074, accuracy: 92.26%\n",
      "Test: [0/13]\tTime 1.824 (1.824)\tLoss 7.0014 (7.0014)\tAcc@1 76.562 (76.562)\n",
      "Test: [10/13]\tTime 0.008 (0.175)\tLoss 7.0453 (7.7037)\tAcc@1 71.875 (73.011)\n",
      " * Acc@1 73.077 Precision: 0.747, Recall: 0.731, F1: 0.678\n",
      "Validation epoch 81: Loss: 7.7222, Accuracy: 73.08%, Precision: 0.747, Recall: 0.731, F1: 0.678, \n",
      "Train: [82][10/33]\tBT 0.010 (0.215)\tDT 0.000 (0.204)\tloss 0.974 (2.025)\tAcc@1 90.625 (92.656)\n",
      "Train: [82][20/33]\tBT 0.072 (0.159)\tDT 0.063 (0.149)\tloss 2.596 (1.862)\tAcc@1 89.062 (92.734)\n",
      "Train: [82][30/33]\tBT 0.009 (0.110)\tDT 0.000 (0.101)\tloss 1.470 (1.920)\tAcc@1 92.188 (92.240)\n",
      "Train epoch 82, loss: 1.8220, accuracy: 92.64%\n",
      "Test: [0/13]\tTime 1.833 (1.833)\tLoss 5.9398 (5.9398)\tAcc@1 67.188 (67.188)\n",
      "Test: [10/13]\tTime 0.004 (0.193)\tLoss 5.6469 (4.9405)\tAcc@1 62.500 (73.722)\n",
      " * Acc@1 73.918 Precision: 0.723, Recall: 0.739, F1: 0.715\n",
      "Validation epoch 82: Loss: 4.6931, Accuracy: 73.92%, Precision: 0.723, Recall: 0.739, F1: 0.715, \n",
      "Train: [83][10/33]\tBT 0.010 (0.210)\tDT 0.000 (0.200)\tloss 0.690 (1.065)\tAcc@1 96.875 (93.906)\n",
      "Train: [83][20/33]\tBT 0.009 (0.162)\tDT 0.000 (0.152)\tloss 2.096 (1.404)\tAcc@1 93.750 (93.203)\n",
      "Train: [83][30/33]\tBT 0.009 (0.111)\tDT 0.000 (0.101)\tloss 0.005 (1.238)\tAcc@1 100.000 (93.229)\n",
      "Train epoch 83, loss: 1.2634, accuracy: 93.22%\n",
      "Test: [0/13]\tTime 1.862 (1.862)\tLoss 5.5770 (5.5770)\tAcc@1 76.562 (76.562)\n",
      "Test: [10/13]\tTime 0.004 (0.195)\tLoss 6.5989 (7.2868)\tAcc@1 75.000 (71.591)\n",
      " * Acc@1 72.356 Precision: 0.702, Recall: 0.724, F1: 0.680\n",
      "Validation epoch 83: Loss: 7.2291, Accuracy: 72.36%, Precision: 0.702, Recall: 0.724, F1: 0.680, \n",
      "Train: [84][10/33]\tBT 0.010 (0.219)\tDT 0.000 (0.209)\tloss 0.689 (1.441)\tAcc@1 93.750 (93.281)\n",
      "Train: [84][20/33]\tBT 0.008 (0.167)\tDT 0.000 (0.157)\tloss 0.146 (1.436)\tAcc@1 95.312 (93.438)\n",
      "Train: [84][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.105)\tloss 0.687 (1.498)\tAcc@1 93.750 (93.125)\n",
      "Train epoch 84, loss: 1.5389, accuracy: 92.93%\n",
      "Test: [0/13]\tTime 1.855 (1.855)\tLoss 8.4079 (8.4079)\tAcc@1 70.312 (70.312)\n",
      "Test: [10/13]\tTime 0.004 (0.203)\tLoss 4.5200 (8.0951)\tAcc@1 73.438 (72.159)\n",
      " * Acc@1 72.596 Precision: 0.727, Recall: 0.726, F1: 0.667\n",
      "Validation epoch 84: Loss: 7.9465, Accuracy: 72.60%, Precision: 0.727, Recall: 0.726, F1: 0.667, \n",
      "Train: [85][10/33]\tBT 0.010 (0.209)\tDT 0.000 (0.199)\tloss 1.182 (1.354)\tAcc@1 96.875 (94.688)\n",
      "Train: [85][20/33]\tBT 0.009 (0.164)\tDT 0.000 (0.154)\tloss 0.728 (1.456)\tAcc@1 96.875 (93.984)\n",
      "Train: [85][30/33]\tBT 0.009 (0.113)\tDT 0.000 (0.103)\tloss 3.588 (1.628)\tAcc@1 89.062 (92.969)\n",
      "Train epoch 85, loss: 1.6438, accuracy: 93.03%\n",
      "Test: [0/13]\tTime 1.902 (1.902)\tLoss 6.3065 (6.3065)\tAcc@1 76.562 (76.562)\n",
      "Test: [10/13]\tTime 0.004 (0.204)\tLoss 7.3522 (8.3476)\tAcc@1 76.562 (72.017)\n",
      " * Acc@1 72.236 Precision: 0.731, Recall: 0.722, F1: 0.683\n",
      "Validation epoch 85: Loss: 8.3772, Accuracy: 72.24%, Precision: 0.731, Recall: 0.722, F1: 0.683, \n",
      "Train: [86][10/33]\tBT 0.009 (0.222)\tDT 0.000 (0.212)\tloss 2.307 (1.845)\tAcc@1 87.500 (91.406)\n",
      "Train: [86][20/33]\tBT 0.008 (0.167)\tDT 0.000 (0.158)\tloss 0.832 (1.469)\tAcc@1 93.750 (92.266)\n",
      "Train: [86][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.105)\tloss 1.730 (1.551)\tAcc@1 93.750 (92.552)\n",
      "Train epoch 86, loss: 1.6049, accuracy: 92.45%\n",
      "Test: [0/13]\tTime 1.778 (1.778)\tLoss 7.1021 (7.1021)\tAcc@1 75.000 (75.000)\n",
      "Test: [10/13]\tTime 0.004 (0.184)\tLoss 5.4265 (7.6790)\tAcc@1 75.000 (72.301)\n",
      " * Acc@1 71.514 Precision: 0.712, Recall: 0.715, F1: 0.678\n",
      "Validation epoch 86: Loss: 8.2207, Accuracy: 71.51%, Precision: 0.712, Recall: 0.715, F1: 0.678, \n",
      "Train: [87][10/33]\tBT 0.010 (0.226)\tDT 0.000 (0.216)\tloss 0.651 (1.514)\tAcc@1 96.875 (92.500)\n",
      "Train: [87][20/33]\tBT 0.009 (0.170)\tDT 0.000 (0.160)\tloss 1.419 (1.258)\tAcc@1 89.062 (92.656)\n",
      "Train: [87][30/33]\tBT 0.009 (0.116)\tDT 0.000 (0.107)\tloss 1.703 (1.255)\tAcc@1 92.188 (92.813)\n",
      "Train epoch 87, loss: 1.2646, accuracy: 92.93%\n",
      "Test: [0/13]\tTime 1.834 (1.834)\tLoss 6.8952 (6.8952)\tAcc@1 76.562 (76.562)\n",
      "Test: [10/13]\tTime 0.004 (0.193)\tLoss 4.7661 (6.9281)\tAcc@1 79.688 (72.869)\n",
      " * Acc@1 71.875 Precision: 0.704, Recall: 0.719, F1: 0.671\n",
      "Validation epoch 87: Loss: 7.0746, Accuracy: 71.88%, Precision: 0.704, Recall: 0.719, F1: 0.671, \n",
      "Train: [88][10/33]\tBT 0.010 (0.213)\tDT 0.000 (0.203)\tloss 1.930 (1.926)\tAcc@1 90.625 (92.031)\n",
      "Train: [88][20/33]\tBT 0.009 (0.161)\tDT 0.000 (0.151)\tloss 2.168 (1.613)\tAcc@1 92.188 (93.203)\n",
      "Train: [88][30/33]\tBT 0.008 (0.110)\tDT 0.000 (0.101)\tloss 1.479 (1.557)\tAcc@1 90.625 (92.917)\n",
      "Train epoch 88, loss: 1.5142, accuracy: 93.08%\n",
      "Test: [0/13]\tTime 1.813 (1.813)\tLoss 9.5197 (9.5197)\tAcc@1 67.188 (67.188)\n",
      "Test: [10/13]\tTime 0.006 (0.206)\tLoss 13.0471 (8.1507)\tAcc@1 67.188 (72.443)\n",
      " * Acc@1 72.356 Precision: 0.713, Recall: 0.724, F1: 0.682\n",
      "Validation epoch 88: Loss: 8.0579, Accuracy: 72.36%, Precision: 0.713, Recall: 0.724, F1: 0.682, \n",
      "Train: [89][10/33]\tBT 0.010 (0.218)\tDT 0.000 (0.208)\tloss 1.789 (1.418)\tAcc@1 89.062 (92.188)\n",
      "Train: [89][20/33]\tBT 0.009 (0.161)\tDT 0.000 (0.152)\tloss 0.903 (1.528)\tAcc@1 93.750 (92.422)\n",
      "Train: [89][30/33]\tBT 0.008 (0.112)\tDT 0.000 (0.103)\tloss 0.880 (1.691)\tAcc@1 95.312 (92.083)\n",
      "Train epoch 89, loss: 1.6082, accuracy: 92.16%\n",
      "Test: [0/13]\tTime 1.753 (1.753)\tLoss 8.9797 (8.9797)\tAcc@1 71.875 (71.875)\n",
      "Test: [10/13]\tTime 0.006 (0.194)\tLoss 10.4961 (7.6881)\tAcc@1 67.188 (72.443)\n",
      " * Acc@1 71.154 Precision: 0.693, Recall: 0.712, F1: 0.665\n",
      "Validation epoch 89: Loss: 8.0754, Accuracy: 71.15%, Precision: 0.693, Recall: 0.712, F1: 0.665, \n",
      "Train: [90][10/33]\tBT 0.010 (0.216)\tDT 0.000 (0.205)\tloss 0.736 (1.257)\tAcc@1 93.750 (93.906)\n",
      "Train: [90][20/33]\tBT 0.008 (0.166)\tDT 0.000 (0.156)\tloss 2.251 (1.417)\tAcc@1 92.188 (93.203)\n",
      "Train: [90][30/33]\tBT 0.008 (0.114)\tDT 0.000 (0.105)\tloss 2.829 (1.390)\tAcc@1 87.500 (93.385)\n",
      "Train epoch 90, loss: 1.3593, accuracy: 93.41%\n",
      "Test: [0/13]\tTime 1.813 (1.813)\tLoss 6.0413 (6.0413)\tAcc@1 73.438 (73.438)\n",
      "Test: [10/13]\tTime 0.006 (0.199)\tLoss 10.6018 (8.5365)\tAcc@1 67.188 (69.602)\n",
      " * Acc@1 70.192 Precision: 0.666, Recall: 0.702, F1: 0.640\n",
      "Validation epoch 90: Loss: 8.3141, Accuracy: 70.19%, Precision: 0.666, Recall: 0.702, F1: 0.640, \n",
      "Train: [91][10/33]\tBT 0.010 (0.216)\tDT 0.000 (0.206)\tloss 2.668 (1.170)\tAcc@1 90.625 (94.062)\n",
      "Train: [91][20/33]\tBT 0.008 (0.162)\tDT 0.000 (0.152)\tloss 0.598 (1.307)\tAcc@1 95.312 (93.672)\n",
      "Train: [91][30/33]\tBT 0.008 (0.111)\tDT 0.000 (0.101)\tloss 1.586 (1.425)\tAcc@1 95.312 (93.229)\n",
      "Train epoch 91, loss: 1.3845, accuracy: 93.27%\n",
      "Test: [0/13]\tTime 1.789 (1.789)\tLoss 12.1059 (12.1059)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.006 (0.186)\tLoss 7.4044 (7.0205)\tAcc@1 68.750 (74.148)\n",
      " * Acc@1 72.957 Precision: 0.714, Recall: 0.730, F1: 0.687\n",
      "Validation epoch 91: Loss: 7.6618, Accuracy: 72.96%, Precision: 0.714, Recall: 0.730, F1: 0.687, \n",
      "Train: [92][10/33]\tBT 0.010 (0.222)\tDT 0.000 (0.212)\tloss 1.703 (1.426)\tAcc@1 90.625 (92.969)\n",
      "Train: [92][20/33]\tBT 0.008 (0.175)\tDT 0.000 (0.165)\tloss 1.806 (1.669)\tAcc@1 95.312 (93.359)\n",
      "Train: [92][30/33]\tBT 0.008 (0.119)\tDT 0.000 (0.110)\tloss 0.326 (1.486)\tAcc@1 98.438 (94.115)\n",
      "Train epoch 92, loss: 1.4806, accuracy: 94.23%\n",
      "Test: [0/13]\tTime 1.916 (1.916)\tLoss 10.0188 (10.0188)\tAcc@1 65.625 (65.625)\n",
      "Test: [10/13]\tTime 0.004 (0.205)\tLoss 12.1738 (7.7087)\tAcc@1 64.062 (72.443)\n",
      " * Acc@1 72.596 Precision: 0.717, Recall: 0.726, F1: 0.671\n",
      "Validation epoch 92: Loss: 8.1562, Accuracy: 72.60%, Precision: 0.717, Recall: 0.726, F1: 0.671, \n",
      "Train: [93][10/33]\tBT 0.010 (0.212)\tDT 0.000 (0.203)\tloss 0.939 (0.822)\tAcc@1 95.312 (95.000)\n",
      "Train: [93][20/33]\tBT 0.009 (0.166)\tDT 0.000 (0.157)\tloss 0.507 (0.904)\tAcc@1 96.875 (94.766)\n",
      "Train: [93][30/33]\tBT 0.009 (0.114)\tDT 0.000 (0.105)\tloss 2.749 (1.172)\tAcc@1 93.750 (94.531)\n",
      "Train epoch 93, loss: 1.2387, accuracy: 94.38%\n",
      "Test: [0/13]\tTime 1.779 (1.779)\tLoss 5.6137 (5.6137)\tAcc@1 68.750 (68.750)\n",
      "Test: [10/13]\tTime 0.009 (0.180)\tLoss 9.2050 (8.7749)\tAcc@1 75.000 (70.455)\n",
      " * Acc@1 71.635 Precision: 0.716, Recall: 0.716, F1: 0.650\n",
      "Validation epoch 93: Loss: 8.4837, Accuracy: 71.63%, Precision: 0.716, Recall: 0.716, F1: 0.650, \n",
      "Train: [94][10/33]\tBT 0.008 (0.223)\tDT 0.000 (0.196)\tloss 1.067 (1.086)\tAcc@1 95.312 (94.375)\n",
      "Train: [94][20/33]\tBT 0.005 (0.161)\tDT 0.000 (0.144)\tloss 2.652 (1.186)\tAcc@1 92.188 (94.297)\n",
      "Train: [94][30/33]\tBT 0.005 (0.109)\tDT 0.000 (0.096)\tloss 0.761 (1.325)\tAcc@1 92.188 (93.906)\n",
      "Train epoch 94, loss: 1.4790, accuracy: 93.46%\n",
      "Test: [0/13]\tTime 1.750 (1.750)\tLoss 5.3132 (5.3132)\tAcc@1 73.438 (73.438)\n",
      "Test: [10/13]\tTime 0.008 (0.174)\tLoss 6.2687 (8.2806)\tAcc@1 76.562 (70.881)\n",
      " * Acc@1 71.034 Precision: 0.681, Recall: 0.710, F1: 0.655\n",
      "Validation epoch 94: Loss: 8.2923, Accuracy: 71.03%, Precision: 0.681, Recall: 0.710, F1: 0.655, \n",
      "Train: [95][10/33]\tBT 0.008 (0.236)\tDT 0.000 (0.199)\tloss 3.608 (1.814)\tAcc@1 92.188 (92.656)\n",
      "Train: [95][20/33]\tBT 0.005 (0.164)\tDT 0.000 (0.142)\tloss 1.134 (1.551)\tAcc@1 93.750 (93.047)\n",
      "Train: [95][30/33]\tBT 0.005 (0.113)\tDT 0.000 (0.097)\tloss 1.414 (1.349)\tAcc@1 93.750 (93.854)\n",
      "Train epoch 95, loss: 1.3792, accuracy: 93.61%\n",
      "Test: [0/13]\tTime 1.855 (1.855)\tLoss 9.2980 (9.2980)\tAcc@1 70.312 (70.312)\n",
      "Test: [10/13]\tTime 0.008 (0.178)\tLoss 8.4008 (8.8588)\tAcc@1 71.875 (72.585)\n",
      " * Acc@1 72.596 Precision: 0.730, Recall: 0.726, F1: 0.673\n",
      "Validation epoch 95: Loss: 9.0731, Accuracy: 72.60%, Precision: 0.730, Recall: 0.726, F1: 0.673, \n",
      "Train: [96][10/33]\tBT 0.044 (0.238)\tDT 0.000 (0.193)\tloss 2.410 (1.669)\tAcc@1 95.312 (92.812)\n",
      "Train: [96][20/33]\tBT 0.008 (0.160)\tDT 0.000 (0.132)\tloss 0.025 (1.609)\tAcc@1 98.438 (93.516)\n",
      "Train: [96][30/33]\tBT 0.043 (0.110)\tDT 0.038 (0.089)\tloss 1.903 (1.499)\tAcc@1 92.188 (93.490)\n",
      "Train epoch 96, loss: 1.4503, accuracy: 93.51%\n",
      "Test: [0/13]\tTime 1.901 (1.901)\tLoss 7.8360 (7.8360)\tAcc@1 78.125 (78.125)\n",
      "Test: [10/13]\tTime 0.008 (0.181)\tLoss 6.1479 (7.1315)\tAcc@1 73.438 (73.295)\n",
      " * Acc@1 72.356 Precision: 0.704, Recall: 0.724, F1: 0.681\n",
      "Validation epoch 96: Loss: 7.7633, Accuracy: 72.36%, Precision: 0.704, Recall: 0.724, F1: 0.681, \n",
      "Train: [97][10/33]\tBT 0.009 (0.239)\tDT 0.000 (0.199)\tloss 1.467 (1.681)\tAcc@1 96.875 (90.781)\n",
      "Train: [97][20/33]\tBT 0.005 (0.171)\tDT 0.000 (0.147)\tloss 0.985 (1.615)\tAcc@1 95.312 (91.719)\n",
      "Train: [97][30/33]\tBT 0.094 (0.119)\tDT 0.089 (0.101)\tloss 2.071 (1.529)\tAcc@1 90.625 (92.292)\n",
      "Train epoch 97, loss: 1.4884, accuracy: 92.55%\n",
      "Test: [0/13]\tTime 1.890 (1.890)\tLoss 8.9959 (8.9959)\tAcc@1 68.750 (68.750)\n",
      "Test: [10/13]\tTime 0.008 (0.180)\tLoss 7.6563 (8.8483)\tAcc@1 75.000 (71.591)\n",
      " * Acc@1 70.673 Precision: 0.705, Recall: 0.707, F1: 0.652\n",
      "Validation epoch 97: Loss: 9.0980, Accuracy: 70.67%, Precision: 0.705, Recall: 0.707, F1: 0.652, \n",
      "Train: [98][10/33]\tBT 0.044 (0.235)\tDT 0.000 (0.204)\tloss 1.711 (0.987)\tAcc@1 95.312 (94.688)\n",
      "Train: [98][20/33]\tBT 0.005 (0.166)\tDT 0.000 (0.142)\tloss 3.300 (1.227)\tAcc@1 89.062 (94.453)\n",
      "Train: [98][30/33]\tBT 0.004 (0.112)\tDT 0.000 (0.095)\tloss 0.464 (1.202)\tAcc@1 95.312 (94.583)\n",
      "Train epoch 98, loss: 1.2628, accuracy: 94.47%\n",
      "Test: [0/13]\tTime 1.850 (1.850)\tLoss 8.6840 (8.6840)\tAcc@1 70.312 (70.312)\n",
      "Test: [10/13]\tTime 0.008 (0.179)\tLoss 6.4800 (7.6336)\tAcc@1 73.438 (70.455)\n",
      " * Acc@1 70.312 Precision: 0.674, Recall: 0.703, F1: 0.654\n",
      "Validation epoch 98: Loss: 7.8627, Accuracy: 70.31%, Precision: 0.674, Recall: 0.703, F1: 0.654, \n",
      "Train: [99][10/33]\tBT 0.010 (0.217)\tDT 0.000 (0.207)\tloss 1.140 (1.471)\tAcc@1 93.750 (92.656)\n",
      "Train: [99][20/33]\tBT 0.009 (0.167)\tDT 0.000 (0.157)\tloss 0.432 (1.495)\tAcc@1 95.312 (92.578)\n",
      "Train: [99][30/33]\tBT 0.009 (0.114)\tDT 0.000 (0.105)\tloss 1.157 (1.436)\tAcc@1 92.188 (92.969)\n",
      "Train epoch 99, loss: 1.4355, accuracy: 93.17%\n",
      "Test: [0/13]\tTime 1.834 (1.834)\tLoss 6.4386 (6.4386)\tAcc@1 79.688 (79.688)\n",
      "Test: [10/13]\tTime 0.004 (0.201)\tLoss 11.7229 (8.2973)\tAcc@1 59.375 (72.727)\n",
      " * Acc@1 72.716 Precision: 0.713, Recall: 0.727, F1: 0.677\n",
      "Validation epoch 99: Loss: 8.4990, Accuracy: 72.72%, Precision: 0.713, Recall: 0.727, F1: 0.677, \n",
      "Train: [100][10/33]\tBT 0.010 (0.220)\tDT 0.000 (0.210)\tloss 0.261 (1.203)\tAcc@1 95.312 (94.375)\n",
      "Train: [100][20/33]\tBT 0.008 (0.174)\tDT 0.000 (0.164)\tloss 0.531 (1.124)\tAcc@1 95.312 (94.609)\n",
      "Train: [100][30/33]\tBT 0.008 (0.119)\tDT 0.000 (0.110)\tloss 0.999 (1.088)\tAcc@1 98.438 (94.688)\n",
      "Train epoch 100, loss: 1.0669, accuracy: 94.76%\n",
      "Test: [0/13]\tTime 1.879 (1.879)\tLoss 6.2580 (6.2580)\tAcc@1 78.125 (78.125)\n",
      "Test: [10/13]\tTime 0.004 (0.195)\tLoss 8.4390 (9.5312)\tAcc@1 73.438 (74.006)\n",
      " * Acc@1 73.678 Precision: 0.736, Recall: 0.737, F1: 0.684\n",
      "Validation epoch 100: Loss: 9.8229, Accuracy: 73.68%, Precision: 0.736, Recall: 0.737, F1: 0.684, \n",
      "Best validation results obtained at epoch 10:\n",
      "Accuracy: 76.803\n",
      "Precision: 0.793\n",
      "Recall: 0.768\n",
      "F1: 0.771\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918b0a94-71b8-4161-9822-c217ed395f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(best_metrics['confusion_matrix'], ['Normal', 'CNV', 'DR', 'AMD'])  # Use the plotting function defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad86272-12ac-412a-b959-c3bbfac3b840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
